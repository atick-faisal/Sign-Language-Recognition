{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import (\n",
    "    create_img_grid,\n",
    "    SpatialProjection\n",
    ")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "sns.set_style()\n",
    "\n",
    "plt.rcParams.update({\n",
    "    # \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times New Roman\"],\n",
    "    \"font.size\": 22,\n",
    "    \"text.color\": \"#212121\",\n",
    "    \"axes.edgecolor\": \"#212121\",\n",
    "    \"xtick.color\": \"#212121\",\n",
    "    \"ytick.color\": \"#212121\",\n",
    "    \"axes.labelcolor\": \"#212121\",\n",
    "    'legend.frameon': False,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data/dataset/raw/\"\n",
    "images_dir = \"../../data/dataset/images/\"\n",
    "subjects = os.listdir(data_dir)\n",
    "\n",
    "IMG_LEN = 225\n",
    "\n",
    "# sp = SpatialProjection(\n",
    "#     img_dir=\"../../data/dataset/images/\",\n",
    "#     img_len=math.floor(IMG_LEN / 3),\n",
    "#     polyfit_degree=0\n",
    "# )\n",
    "\n",
    "augmentation_levels = [0, 7, 9, 11, 13]\n",
    "sp_augment = [\n",
    "    SpatialProjection(\n",
    "    img_dir=\"../../data/dataset/images/\",\n",
    "    # img_len=math.floor(config.IMG_LEN / 3),\n",
    "    img_len=config.IMG_LEN,\n",
    "    polyfit_degree=degree\n",
    ")\n",
    "    for degree in augmentation_levels ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "for subject in subjects:\n",
    "    for gesture in config.GESTURES:\n",
    "        gesture_dir = os.path.join(data_dir, subject, gesture)\n",
    "\n",
    "        recordings = []\n",
    "        try:\n",
    "            recordings = os.listdir(gesture_dir)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "        for recording in recordings:\n",
    "            _images = []\n",
    "            file_path = os.path.join(gesture_dir, recording)\n",
    "\n",
    "            data = pd.read_csv(file_path)\n",
    "            data.drop(columns=[\"time\"], inplace=True)\n",
    "            data.drop(0, inplace=True)  # Remove first All-0 row\n",
    "\n",
    "            for sp in sp_augment:\n",
    "                for landmark in config.PROJECTION_LANDMARKS:\n",
    "                    _images.extend(\n",
    "                        sp.get_projection_images(\n",
    "                            data=data.filter(regex=landmark),\n",
    "                            subject=subject,\n",
    "                            gesture=gesture\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                img = create_img_grid(_images, IMG_LEN)\n",
    "\n",
    "                images.append(img)\n",
    "                labels.append(config.GESTURES.index(gesture))\n",
    "\n",
    "                plt.figure(figsize=(8, 8))\n",
    "                plt.imshow(img)\n",
    "                # plt.title(f\"Original Spatial Projection\")\n",
    "                save_path = os.path.join(images_dir, subject, gesture)\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                # plt.savefig(os.path.join(save_path, recording + \".jpg\"))\n",
    "                # plt.close()\n",
    "                # plt.axis(\"off\")\n",
    "                # plt.tight_layout()\n",
    "                # plt.savefig(\"../assets/projection_demo.svg\")\n",
    "                plt.show()\n",
    "            \n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import LowPassFilter\n",
    "\n",
    "def get_ployfit_approximation(\n",
    "    data: np.ndarray,\n",
    "    polyfit_degree: int = 9\n",
    ") -> np.ndarray:\n",
    "    processed_data = data.to_numpy().ravel()\n",
    "\n",
    "    if polyfit_degree == 0:\n",
    "        # ... First few (10) datapoints contains filter artifacts\n",
    "        processed_data = LowPassFilter.apply(processed_data)[10:]\n",
    "    else:\n",
    "        t = np.linspace(0, 1, processed_data.shape[0])\n",
    "        f = np.poly1d(np.polyfit(t, processed_data, polyfit_degree))\n",
    "        processed_data = f(t)\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = data[\"rpx\"]\n",
    "y = data[\"rpy\"]\n",
    "z = data[\"rpz\"]\n",
    "\n",
    "_x = get_ployfit_approximation(x)\n",
    "_y = get_ployfit_approximation(y)\n",
    "_z = get_ployfit_approximation(z)\n",
    "\n",
    "t = np.linspace(0, 3, x.shape[0])\n",
    "\n",
    "plt.figure(figsize=(16, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.plot(t, x, label=\"X\", linewidth=3)\n",
    "plt.plot(t, y, label=\"Y\", linewidth=3)\n",
    "plt.plot(t, z, label=\"Z\", linewidth=3)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Landmark Coordinate (mm)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.plot(t, _x, label=\"X (Approx)\", linewidth=3)\n",
    "plt.plot(t, _y, label=\"Y (Approx)\", linewidth=3)\n",
    "plt.plot(t, _z, label=\"Z (Approx)\", linewidth=3)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Landmark Coordinate (mm)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../assets/polyfit_approx.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 19:56:10.226172: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import tensorflow as tf\n",
    "from model.projectionnet import ProjectionNet\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 19:56:12.569564: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-25 19:56:12.569617: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: Andromeda\n",
      "2022-06-25 19:56:12.569625: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: Andromeda\n",
      "2022-06-25 19:56:12.569767: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.48.7\n",
      "2022-06-25 19:56:12.569793: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.48.7\n",
      "2022-06-25 19:56:12.569799: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.48.7\n",
      "2022-06-25 19:56:12.570554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(config.IMG_LEN, config.IMG_LEN, config.N_CHANNELS),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 150, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 150, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_13 (InputLayer)          [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv_net1d (ConvNet1D)         (None, 32)           0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv_net1d_1 (ConvNet1D)       (None, 32)           0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv_net1d_2 (ConvNet1D)       (None, 32)           0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv_net1d_3 (ConvNet1D)       (None, 32)           0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv_net1d_4 (ConvNet1D)       (None, 32)           0           ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv_net1d_5 (ConvNet1D)       (None, 32)           0           ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " conv_net1d_6 (ConvNet1D)       (None, 32)           0           ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " conv_net1d_7 (ConvNet1D)       (None, 32)           0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv_net1d_8 (ConvNet1D)       (None, 32)           0           ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " conv_net1d_9 (ConvNet1D)       (None, 32)           0           ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " conv_net2d (ConvNet2D)         (None, 1280)         2257984     ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " conv_net2d_1 (ConvNet2D)       (None, 1280)         2257984     ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " conv_net2d_2 (ConvNet2D)       (None, 1280)         2257984     ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4160)         0           ['conv_net1d[0][0]',             \n",
      "                                                                  'conv_net1d_1[0][0]',           \n",
      "                                                                  'conv_net1d_2[0][0]',           \n",
      "                                                                  'conv_net1d_3[0][0]',           \n",
      "                                                                  'conv_net1d_4[0][0]',           \n",
      "                                                                  'conv_net1d_5[0][0]',           \n",
      "                                                                  'conv_net1d_6[0][0]',           \n",
      "                                                                  'conv_net1d_7[0][0]',           \n",
      "                                                                  'conv_net1d_8[0][0]',           \n",
      "                                                                  'conv_net1d_9[0][0]',           \n",
      "                                                                  'conv_net2d[0][0]',             \n",
      "                                                                  'conv_net2d_1[0][0]',           \n",
      "                                                                  'conv_net2d_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          532608      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 14)           1806        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,792,398\n",
      "Trainable params: 534,414\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ProjectionNet(\n",
    "    n_classes=14,\n",
    "    n_feature_vectors=10,\n",
    "    base_model=base_model\n",
    ").model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f0f52ed645d8567bae68a8c372449e0a23f49f10e778396b1f58fd2946c160c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
