{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import config\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import (\n",
    "    create_img_grid,\n",
    "    SpatialProjection\n",
    ")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data/dataset/raw/\"\n",
    "subjects = os.listdir(data_dir)\n",
    "\n",
    "augmentation_levels = [11, 13, 9, 7, 0]\n",
    "sp_augment = [\n",
    "    SpatialProjection(\n",
    "    img_dir=\"../../data/dataset/images/\",\n",
    "    img_len=math.floor(config.IMG_LEN / 3),\n",
    "    polyfit_degree=degree\n",
    ")\n",
    "    for degree in augmentation_levels ]\n",
    "\n",
    "test_subject = \"007\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [13:49<00:00, 118.57s/it]\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for subject in tqdm(subjects):\n",
    "    for gesture in config.GESTURES:\n",
    "        gesture_dir = os.path.join(data_dir, subject, gesture)\n",
    "        recordings = os.listdir(gesture_dir)\n",
    "        for recording in recordings:\n",
    "            _images = []\n",
    "            file_path = os.path.join(gesture_dir, recording)\n",
    "\n",
    "            data = pd.read_csv(file_path)\n",
    "            data.drop(columns=[\"time\"], inplace=True)\n",
    "            data.drop(0, inplace=True)  # Remove first All-0 row\n",
    "\n",
    "            if data.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            # Flag for determining Trainning and Testing Samples\n",
    "            for_training = subject != test_subject\n",
    "\n",
    "            for sp in sp_augment:\n",
    "                for landmark in config.PROJECTION_LANDMARKS:\n",
    "                    _images.extend(\n",
    "                        sp.get_projection_images(\n",
    "                            data=data.filter(regex=landmark),\n",
    "                            subject=subject,\n",
    "                            gesture=gesture\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                img = create_img_grid(_images, config.IMG_LEN)\n",
    "\n",
    "                if for_training:\n",
    "                    train_images.append(img)\n",
    "                    train_labels.append(config.GESTURES.index(gesture))\n",
    "                else:\n",
    "                    test_images.append(img)\n",
    "                    test_labels.append(config.GESTURES.index(gesture))\n",
    "                    break\n",
    "\n",
    "    #         plt.imshow(img)\n",
    "    #         plt.savefig(\"../assets/projection_demo.pdf\")\n",
    "    #         plt.show()\n",
    "\n",
    "    #         break\n",
    "    #     break\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4990, 224, 224, 1)\n",
      "(161, 224, 224, 1)\n",
      "(4990,)\n",
      "(161,)\n"
     ]
    }
   ],
   "source": [
    "# X = np.array(images, dtype=\"uint8\")\n",
    "# X = np.expand_dims(X[:, :, :, 0], axis=-1)\n",
    "# # X = np.repeat(np.expand_dims(X, axis=-1), 3, axis=-1)\n",
    "# y = np.array(labels, dtype=\"uint8\")\n",
    "\n",
    "X_train = np.array(train_images, dtype=\"uint8\")\n",
    "X_test = np.array(test_images, dtype=\"uint8\")\n",
    "y_train = np.array(train_labels, dtype=\"uint8\")\n",
    "y_test = np.array(test_labels, dtype=\"uint8\")\n",
    "\n",
    "X_train = np.expand_dims(X_train[:, :, :, 0], axis=-1)\n",
    "X_test = np.expand_dims(X_test[:, :, :, 0], axis=-1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/dataset/processed/007/y_test_11.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = f\"../../data/dataset/processed/{test_subject}/\"\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "joblib.dump(X_train, os.path.join(save_dir, \"X_train_11.joblib\"))\n",
    "joblib.dump(y_train, os.path.join(save_dir, \"y_train_11.joblib\"))\n",
    "joblib.dump(X_test, os.path.join(save_dir, \"X_test_11.joblib\"))\n",
    "joblib.dump(y_test, os.path.join(save_dir, \"y_test_11.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.33, random_state=42\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "# base_model = tf.keras.applications.MobileNetV2(\n",
    "#     input_shape=(config.IMG_LEN, config.IMG_LEN, 3),\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\"\n",
    "# )\n",
    "# base_model.trainable = True\n",
    "# global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "# prediction_layer = tf.keras.layers.Dense(len(config.GESTURES))\n",
    "\n",
    "# inputs = tf.keras.Input(shape=(config.IMG_LEN, config.IMG_LEN, 3))\n",
    "# x = preprocess_input(inputs)\n",
    "# x = base_model(x, training=True)\n",
    "# x = global_average_layer(x)\n",
    "# x = tf.keras.layers.Dropout(0.6)(x)\n",
    "# outputs = prediction_layer(x)\n",
    "# model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Rescaling(\n",
    "        1/255.0,\n",
    "        input_shape=(config.IMG_LEN, config.IMG_LEN, config.N_CHANNELS)\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(config.GESTURES))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import config\n",
    "# from model import ConvMixer\n",
    "\n",
    "# model = ConvMixer(\n",
    "#     img_size=config.IMG_LEN,\n",
    "#     in_channels=1,\n",
    "#     n_classes=len(config.GESTURES),\n",
    "#     n_filters=64,\n",
    "#     depth=3,\n",
    "#     kernel_size=5,\n",
    "#     patch_size=2\n",
    "# ).model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=config.LEARNING_RATE),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=30,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=32,\n",
    "    epochs=700,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\n",
    "    # \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    # \"font.serif\": [\"Computer Modern Roman\"],\n",
    "    \"font.size\": 22,\n",
    "    \"text.color\": \"#212121\",\n",
    "    \"axes.edgecolor\": \"#212121\",\n",
    "    \"xtick.color\": \"#212121\",\n",
    "    \"ytick.color\": \"#212121\",\n",
    "    \"axes.labelcolor\": \"#212121\",\n",
    "    'legend.frameon': False,\n",
    "})\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.gca()\n",
    "ax.plot(history.history[\"loss\"], \"-\", color=\"#212121\", label=\"Train Loss\")\n",
    "ax.plot(history.history[\"val_loss\"], \"--\",\n",
    "        color=\"#212121\", label=\"Validation Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.title(\"Learning Curves\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../assets/lc.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f0f52ed645d8567bae68a8c372449e0a23f49f10e778396b1f58fd2946c160c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
