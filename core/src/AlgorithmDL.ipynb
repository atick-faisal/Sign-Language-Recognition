{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import resample\n",
    "from scipy.stats import mode\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data/dataset/raw/\"\n",
    "subjects = os.listdir(data_dir)\n",
    "gestures = config.GESTURES\n",
    "learning_rate = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rpx</th>\n",
       "      <th>rpy</th>\n",
       "      <th>rpz</th>\n",
       "      <th>lpx</th>\n",
       "      <th>lpy</th>\n",
       "      <th>lpz</th>\n",
       "      <th>rf0x</th>\n",
       "      <th>rf0y</th>\n",
       "      <th>rf0z</th>\n",
       "      <th>...</th>\n",
       "      <th>lf4x</th>\n",
       "      <th>lf4y</th>\n",
       "      <th>lf4z</th>\n",
       "      <th>drf0x</th>\n",
       "      <th>drf0y</th>\n",
       "      <th>drf0z</th>\n",
       "      <th>drf1x</th>\n",
       "      <th>drf1y</th>\n",
       "      <th>drf1z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.919871</td>\n",
       "      <td>32.937358</td>\n",
       "      <td>13.040457</td>\n",
       "      <td>39.663028</td>\n",
       "      <td>34.199817</td>\n",
       "      <td>19.763141</td>\n",
       "      <td>6.957625</td>\n",
       "      <td>31.458863</td>\n",
       "      <td>6.394413</td>\n",
       "      <td>...</td>\n",
       "      <td>36.970489</td>\n",
       "      <td>19.440563</td>\n",
       "      <td>11.496098</td>\n",
       "      <td>-0.962246</td>\n",
       "      <td>-1.478495</td>\n",
       "      <td>-6.646044</td>\n",
       "      <td>-1.219138</td>\n",
       "      <td>-6.571643</td>\n",
       "      <td>-17.891781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35.802107</td>\n",
       "      <td>168.358689</td>\n",
       "      <td>52.411913</td>\n",
       "      <td>185.849615</td>\n",
       "      <td>160.250569</td>\n",
       "      <td>92.604431</td>\n",
       "      <td>-27.924779</td>\n",
       "      <td>151.538837</td>\n",
       "      <td>28.993743</td>\n",
       "      <td>...</td>\n",
       "      <td>173.233150</td>\n",
       "      <td>91.092922</td>\n",
       "      <td>53.867430</td>\n",
       "      <td>-63.726887</td>\n",
       "      <td>-16.819852</td>\n",
       "      <td>-23.418170</td>\n",
       "      <td>-32.447528</td>\n",
       "      <td>-10.479782</td>\n",
       "      <td>-88.812099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>35.709530</td>\n",
       "      <td>165.945607</td>\n",
       "      <td>53.001519</td>\n",
       "      <td>184.716385</td>\n",
       "      <td>159.273431</td>\n",
       "      <td>92.039769</td>\n",
       "      <td>-21.683797</td>\n",
       "      <td>150.278150</td>\n",
       "      <td>28.938370</td>\n",
       "      <td>...</td>\n",
       "      <td>172.176850</td>\n",
       "      <td>90.537478</td>\n",
       "      <td>53.538970</td>\n",
       "      <td>-57.393327</td>\n",
       "      <td>-15.667456</td>\n",
       "      <td>-24.063150</td>\n",
       "      <td>-29.553679</td>\n",
       "      <td>-12.477695</td>\n",
       "      <td>-87.847741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>35.858950</td>\n",
       "      <td>167.791059</td>\n",
       "      <td>52.827634</td>\n",
       "      <td>185.849615</td>\n",
       "      <td>160.250569</td>\n",
       "      <td>92.604431</td>\n",
       "      <td>-25.418628</td>\n",
       "      <td>151.425699</td>\n",
       "      <td>29.072187</td>\n",
       "      <td>...</td>\n",
       "      <td>173.233150</td>\n",
       "      <td>91.092922</td>\n",
       "      <td>53.867430</td>\n",
       "      <td>-61.277578</td>\n",
       "      <td>-16.365361</td>\n",
       "      <td>-23.755447</td>\n",
       "      <td>-31.356811</td>\n",
       "      <td>-11.310929</td>\n",
       "      <td>-88.603188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>35.683890</td>\n",
       "      <td>166.213800</td>\n",
       "      <td>52.880427</td>\n",
       "      <td>184.716385</td>\n",
       "      <td>159.273431</td>\n",
       "      <td>92.039769</td>\n",
       "      <td>-22.773460</td>\n",
       "      <td>150.403668</td>\n",
       "      <td>28.943631</td>\n",
       "      <td>...</td>\n",
       "      <td>172.176850</td>\n",
       "      <td>90.537478</td>\n",
       "      <td>53.538970</td>\n",
       "      <td>-58.457350</td>\n",
       "      <td>-15.810133</td>\n",
       "      <td>-23.936796</td>\n",
       "      <td>-30.038383</td>\n",
       "      <td>-12.106708</td>\n",
       "      <td>-87.953241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35579</th>\n",
       "      <td>251</td>\n",
       "      <td>48.119727</td>\n",
       "      <td>214.613029</td>\n",
       "      <td>33.995488</td>\n",
       "      <td>184.368548</td>\n",
       "      <td>127.918388</td>\n",
       "      <td>95.951430</td>\n",
       "      <td>-5.293787</td>\n",
       "      <td>194.742468</td>\n",
       "      <td>4.554490</td>\n",
       "      <td>...</td>\n",
       "      <td>167.620172</td>\n",
       "      <td>51.236467</td>\n",
       "      <td>65.957223</td>\n",
       "      <td>-53.413513</td>\n",
       "      <td>-19.870560</td>\n",
       "      <td>-29.440998</td>\n",
       "      <td>-37.667256</td>\n",
       "      <td>-27.711561</td>\n",
       "      <td>-57.491350</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35580</th>\n",
       "      <td>252</td>\n",
       "      <td>47.843869</td>\n",
       "      <td>213.187481</td>\n",
       "      <td>33.986822</td>\n",
       "      <td>183.237452</td>\n",
       "      <td>127.133612</td>\n",
       "      <td>95.362770</td>\n",
       "      <td>-5.581431</td>\n",
       "      <td>193.557259</td>\n",
       "      <td>4.761509</td>\n",
       "      <td>...</td>\n",
       "      <td>166.591828</td>\n",
       "      <td>50.922133</td>\n",
       "      <td>65.552577</td>\n",
       "      <td>-53.425300</td>\n",
       "      <td>-19.630222</td>\n",
       "      <td>-29.225313</td>\n",
       "      <td>-37.753480</td>\n",
       "      <td>-25.736733</td>\n",
       "      <td>-59.263746</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35581</th>\n",
       "      <td>253</td>\n",
       "      <td>48.154319</td>\n",
       "      <td>215.182833</td>\n",
       "      <td>33.958767</td>\n",
       "      <td>184.368548</td>\n",
       "      <td>127.918388</td>\n",
       "      <td>95.951430</td>\n",
       "      <td>-5.477001</td>\n",
       "      <td>195.448162</td>\n",
       "      <td>4.385848</td>\n",
       "      <td>...</td>\n",
       "      <td>167.620172</td>\n",
       "      <td>51.236467</td>\n",
       "      <td>65.957223</td>\n",
       "      <td>-53.631320</td>\n",
       "      <td>-19.734671</td>\n",
       "      <td>-29.572919</td>\n",
       "      <td>-38.123656</td>\n",
       "      <td>-25.417854</td>\n",
       "      <td>-60.678584</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35582</th>\n",
       "      <td>254</td>\n",
       "      <td>47.906485</td>\n",
       "      <td>213.421478</td>\n",
       "      <td>34.124816</td>\n",
       "      <td>183.237452</td>\n",
       "      <td>127.133612</td>\n",
       "      <td>95.362770</td>\n",
       "      <td>-5.902233</td>\n",
       "      <td>194.132714</td>\n",
       "      <td>4.944356</td>\n",
       "      <td>...</td>\n",
       "      <td>166.591828</td>\n",
       "      <td>50.922133</td>\n",
       "      <td>65.552577</td>\n",
       "      <td>-53.808718</td>\n",
       "      <td>-19.288764</td>\n",
       "      <td>-29.180460</td>\n",
       "      <td>-38.122983</td>\n",
       "      <td>-23.035166</td>\n",
       "      <td>-62.467568</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35583</th>\n",
       "      <td>255</td>\n",
       "      <td>48.269417</td>\n",
       "      <td>216.461439</td>\n",
       "      <td>33.990466</td>\n",
       "      <td>184.368548</td>\n",
       "      <td>127.918388</td>\n",
       "      <td>95.951430</td>\n",
       "      <td>-5.300338</td>\n",
       "      <td>196.608133</td>\n",
       "      <td>4.143483</td>\n",
       "      <td>...</td>\n",
       "      <td>167.620172</td>\n",
       "      <td>51.236467</td>\n",
       "      <td>65.957223</td>\n",
       "      <td>-53.569755</td>\n",
       "      <td>-19.853306</td>\n",
       "      <td>-29.846982</td>\n",
       "      <td>-38.415101</td>\n",
       "      <td>-23.696440</td>\n",
       "      <td>-63.083574</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35584 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        rpx         rpy        rpz         lpx         lpy  \\\n",
       "0          0   7.919871   32.937358  13.040457   39.663028   34.199817   \n",
       "1          1  35.802107  168.358689  52.411913  185.849615  160.250569   \n",
       "2          2  35.709530  165.945607  53.001519  184.716385  159.273431   \n",
       "3          3  35.858950  167.791059  52.827634  185.849615  160.250569   \n",
       "4          4  35.683890  166.213800  52.880427  184.716385  159.273431   \n",
       "...      ...        ...         ...        ...         ...         ...   \n",
       "35579    251  48.119727  214.613029  33.995488  184.368548  127.918388   \n",
       "35580    252  47.843869  213.187481  33.986822  183.237452  127.133612   \n",
       "35581    253  48.154319  215.182833  33.958767  184.368548  127.918388   \n",
       "35582    254  47.906485  213.421478  34.124816  183.237452  127.133612   \n",
       "35583    255  48.269417  216.461439  33.990466  184.368548  127.918388   \n",
       "\n",
       "             lpz       rf0x        rf0y       rf0z  ...        lf4x  \\\n",
       "0      19.763141   6.957625   31.458863   6.394413  ...   36.970489   \n",
       "1      92.604431 -27.924779  151.538837  28.993743  ...  173.233150   \n",
       "2      92.039769 -21.683797  150.278150  28.938370  ...  172.176850   \n",
       "3      92.604431 -25.418628  151.425699  29.072187  ...  173.233150   \n",
       "4      92.039769 -22.773460  150.403668  28.943631  ...  172.176850   \n",
       "...          ...        ...         ...        ...  ...         ...   \n",
       "35579  95.951430  -5.293787  194.742468   4.554490  ...  167.620172   \n",
       "35580  95.362770  -5.581431  193.557259   4.761509  ...  166.591828   \n",
       "35581  95.951430  -5.477001  195.448162   4.385848  ...  167.620172   \n",
       "35582  95.362770  -5.902233  194.132714   4.944356  ...  166.591828   \n",
       "35583  95.951430  -5.300338  196.608133   4.143483  ...  167.620172   \n",
       "\n",
       "            lf4y       lf4z      drf0x      drf0y      drf0z      drf1x  \\\n",
       "0      19.440563  11.496098  -0.962246  -1.478495  -6.646044  -1.219138   \n",
       "1      91.092922  53.867430 -63.726887 -16.819852 -23.418170 -32.447528   \n",
       "2      90.537478  53.538970 -57.393327 -15.667456 -24.063150 -29.553679   \n",
       "3      91.092922  53.867430 -61.277578 -16.365361 -23.755447 -31.356811   \n",
       "4      90.537478  53.538970 -58.457350 -15.810133 -23.936796 -30.038383   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "35579  51.236467  65.957223 -53.413513 -19.870560 -29.440998 -37.667256   \n",
       "35580  50.922133  65.552577 -53.425300 -19.630222 -29.225313 -37.753480   \n",
       "35581  51.236467  65.957223 -53.631320 -19.734671 -29.572919 -38.123656   \n",
       "35582  50.922133  65.552577 -53.808718 -19.288764 -29.180460 -38.122983   \n",
       "35583  51.236467  65.957223 -53.569755 -19.853306 -29.846982 -38.415101   \n",
       "\n",
       "           drf1y      drf1z  label  \n",
       "0      -6.571643 -17.891781      0  \n",
       "1     -10.479782 -88.812099      0  \n",
       "2     -12.477695 -87.847741      0  \n",
       "3     -11.310929 -88.603188      0  \n",
       "4     -12.106708 -87.953241      0  \n",
       "...          ...        ...    ...  \n",
       "35579 -27.711561 -57.491350     11  \n",
       "35580 -25.736733 -59.263746     11  \n",
       "35581 -25.417854 -60.678584     11  \n",
       "35582 -23.035166 -62.467568     11  \n",
       "35583 -23.696440 -63.083574     11  \n",
       "\n",
       "[35584 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame()\n",
    "\n",
    "for subject in subjects:\n",
    "    for gesture in config.GESTURES:\n",
    "        gesture_dir = os.path.join(data_dir, subject, gesture)\n",
    "        recordings = os.listdir(gesture_dir)\n",
    "        for recording in recordings:\n",
    "            file_path = os.path.join(gesture_dir, recording)\n",
    "            data = pd.read_csv(file_path)\n",
    "            data.drop(columns=[\"time\"], inplace=True)\n",
    "            data = data.apply(resample, args=(config.SEGMENT_LEN, None, 0))\n",
    "\n",
    "        #     # ... calculating distance of the index finger\n",
    "        #     data[\"drf1\"] = ((data[\"rf1x\"] - data[\"rpx\"]).pow(2) + \\\n",
    "        #             (data[\"rf1z\"] - data[\"rpz\"]).pow(2)).pow(0.5)\n",
    "\n",
    "        #     data[\"dlf1\"] = ((data[\"lf1x\"] - data[\"lpx\"]).pow(2) + \\\n",
    "        #             (data[\"lf1z\"] - data[\"lpz\"]).pow(2)).pow(0.5)\n",
    "\n",
    "            data[\"drf0x\"] = data[\"rf0x\"] - data[\"rpx\"]\n",
    "            data[\"drf0y\"] = data[\"rf0y\"] - data[\"rpy\"]\n",
    "            data[\"drf0z\"] = data[\"rf0z\"] - data[\"rpz\"]\n",
    "\n",
    "            data[\"drf1x\"] = data[\"rf1x\"] - data[\"rpx\"]\n",
    "            data[\"drf1y\"] = data[\"rf1y\"] - data[\"rpy\"]\n",
    "            data[\"drf1z\"] = data[\"rf1z\"] - data[\"rpz\"]\n",
    "\n",
    "            data[\"label\"] = config.GESTURES.index(gesture)\n",
    "\n",
    "            dataset = pd.concat([dataset, data])\n",
    "\n",
    "dataset.reset_index(inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rpx</th>\n",
       "      <th>rpy</th>\n",
       "      <th>rpz</th>\n",
       "      <th>rf0x</th>\n",
       "      <th>rf0y</th>\n",
       "      <th>rf0z</th>\n",
       "      <th>rf1x</th>\n",
       "      <th>rf1y</th>\n",
       "      <th>rf1z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.919871</td>\n",
       "      <td>32.937358</td>\n",
       "      <td>13.040457</td>\n",
       "      <td>6.957625</td>\n",
       "      <td>31.458863</td>\n",
       "      <td>6.394413</td>\n",
       "      <td>6.700733</td>\n",
       "      <td>26.365715</td>\n",
       "      <td>-4.851325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.802107</td>\n",
       "      <td>168.358689</td>\n",
       "      <td>52.411913</td>\n",
       "      <td>-27.924779</td>\n",
       "      <td>151.538837</td>\n",
       "      <td>28.993743</td>\n",
       "      <td>3.354579</td>\n",
       "      <td>157.878907</td>\n",
       "      <td>-36.400186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.709530</td>\n",
       "      <td>165.945607</td>\n",
       "      <td>53.001519</td>\n",
       "      <td>-21.683797</td>\n",
       "      <td>150.278150</td>\n",
       "      <td>28.938370</td>\n",
       "      <td>6.155851</td>\n",
       "      <td>153.467911</td>\n",
       "      <td>-34.846222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.858950</td>\n",
       "      <td>167.791059</td>\n",
       "      <td>52.827634</td>\n",
       "      <td>-25.418628</td>\n",
       "      <td>151.425699</td>\n",
       "      <td>29.072187</td>\n",
       "      <td>4.502139</td>\n",
       "      <td>156.480130</td>\n",
       "      <td>-35.775553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.683890</td>\n",
       "      <td>166.213800</td>\n",
       "      <td>52.880427</td>\n",
       "      <td>-22.773460</td>\n",
       "      <td>150.403668</td>\n",
       "      <td>28.943631</td>\n",
       "      <td>5.645507</td>\n",
       "      <td>154.107092</td>\n",
       "      <td>-35.072814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35579</th>\n",
       "      <td>48.119727</td>\n",
       "      <td>214.613029</td>\n",
       "      <td>33.995488</td>\n",
       "      <td>-5.293787</td>\n",
       "      <td>194.742468</td>\n",
       "      <td>4.554490</td>\n",
       "      <td>10.452471</td>\n",
       "      <td>186.901467</td>\n",
       "      <td>-23.495863</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35580</th>\n",
       "      <td>47.843869</td>\n",
       "      <td>213.187481</td>\n",
       "      <td>33.986822</td>\n",
       "      <td>-5.581431</td>\n",
       "      <td>193.557259</td>\n",
       "      <td>4.761509</td>\n",
       "      <td>10.090389</td>\n",
       "      <td>187.450748</td>\n",
       "      <td>-25.276924</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35581</th>\n",
       "      <td>48.154319</td>\n",
       "      <td>215.182833</td>\n",
       "      <td>33.958767</td>\n",
       "      <td>-5.477001</td>\n",
       "      <td>195.448162</td>\n",
       "      <td>4.385848</td>\n",
       "      <td>10.030663</td>\n",
       "      <td>189.764979</td>\n",
       "      <td>-26.719818</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35582</th>\n",
       "      <td>47.906485</td>\n",
       "      <td>213.421478</td>\n",
       "      <td>34.124816</td>\n",
       "      <td>-5.902233</td>\n",
       "      <td>194.132714</td>\n",
       "      <td>4.944356</td>\n",
       "      <td>9.783502</td>\n",
       "      <td>190.386312</td>\n",
       "      <td>-28.342752</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35583</th>\n",
       "      <td>48.269417</td>\n",
       "      <td>216.461439</td>\n",
       "      <td>33.990466</td>\n",
       "      <td>-5.300338</td>\n",
       "      <td>196.608133</td>\n",
       "      <td>4.143483</td>\n",
       "      <td>9.854316</td>\n",
       "      <td>192.764999</td>\n",
       "      <td>-29.093108</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35584 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rpx         rpy        rpz       rf0x        rf0y       rf0z  \\\n",
       "0       7.919871   32.937358  13.040457   6.957625   31.458863   6.394413   \n",
       "1      35.802107  168.358689  52.411913 -27.924779  151.538837  28.993743   \n",
       "2      35.709530  165.945607  53.001519 -21.683797  150.278150  28.938370   \n",
       "3      35.858950  167.791059  52.827634 -25.418628  151.425699  29.072187   \n",
       "4      35.683890  166.213800  52.880427 -22.773460  150.403668  28.943631   \n",
       "...          ...         ...        ...        ...         ...        ...   \n",
       "35579  48.119727  214.613029  33.995488  -5.293787  194.742468   4.554490   \n",
       "35580  47.843869  213.187481  33.986822  -5.581431  193.557259   4.761509   \n",
       "35581  48.154319  215.182833  33.958767  -5.477001  195.448162   4.385848   \n",
       "35582  47.906485  213.421478  34.124816  -5.902233  194.132714   4.944356   \n",
       "35583  48.269417  216.461439  33.990466  -5.300338  196.608133   4.143483   \n",
       "\n",
       "            rf1x        rf1y       rf1z  label  \n",
       "0       6.700733   26.365715  -4.851325      0  \n",
       "1       3.354579  157.878907 -36.400186      0  \n",
       "2       6.155851  153.467911 -34.846222      0  \n",
       "3       4.502139  156.480130 -35.775553      0  \n",
       "4       5.645507  154.107092 -35.072814      0  \n",
       "...          ...         ...        ...    ...  \n",
       "35579  10.452471  186.901467 -23.495863     11  \n",
       "35580  10.090389  187.450748 -25.276924     11  \n",
       "35581  10.030663  189.764979 -26.719818     11  \n",
       "35582   9.783502  190.386312 -28.342752     11  \n",
       "35583   9.854316  192.764999 -29.093108     11  \n",
       "\n",
       "[35584 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = dataset[config.INFERENCE_FEATURES + [\"label\"]]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 02:28:37.951903: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models, losses, optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = features.drop(columns=[\"label\"]).to_numpy()\n",
    "X = scaler.fit_transform(X)\n",
    "X = X.reshape((-1, config.SEGMENT_LEN, len(config.INFERENCE_FEATURES)))\n",
    "y = features[\"label\"].to_numpy().reshape((-1, config.SEGMENT_LEN))\n",
    "y, _ = mode(y, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_1d():\n",
    "    inputs = layers.Input(shape=(config.SEGMENT_LEN, 1))\n",
    "    x = layers.BatchNormalization()(inputs)\n",
    "    x = layers.Conv1D(8, 3, activation=\"selu\")(x)\n",
    "    x = layers.Conv1D(8, 3, activation=\"selu\")(x)\n",
    "    x = layers.MaxPool1D(2)(x)\n",
    "    x = layers.Conv1D(8, 3, activation=\"selu\")(x)\n",
    "    x = layers.Conv1D(8, 3, activation=\"selu\")(x)\n",
    "    x = layers.MaxPool1D(2)(x)\n",
    "    x = layers.Conv1D(16, 3, activation=\"selu\")(x)\n",
    "    x = layers.Conv1D(16, 3, activation=\"selu\")(x)\n",
    "    x = layers.MaxPool1D(2)(x)\n",
    "    x = layers.Conv1D(16, 3, activation=\"selu\")(x)\n",
    "    x = layers.Conv1D(16, 3, activation=\"selu\")(x)\n",
    "    x = layers.MaxPool1D(2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(64)(x)\n",
    "\n",
    "    return inputs, output\n",
    "\n",
    "def get_model(n_channels: int):\n",
    "    inputs = []\n",
    "    features = []\n",
    "\n",
    "    for _ in range(n_channels):\n",
    "        input_1d, features_1d = conv_block_1d()\n",
    "        inputs.append(input_1d)\n",
    "        features.append(features_1d)\n",
    "\n",
    "    x = layers.concatenate(features, axis=-1)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(len(gestures), activation=\"softmax\")(x)\n",
    "\n",
    "    return models.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 02:28:39.078212: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-15 02:28:39.078249: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: Andromeda\n",
      "2022-06-15 02:28:39.078253: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: Andromeda\n",
      "2022-06-15 02:28:39.078413: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.48.7\n",
      "2022-06-15 02:28:39.078432: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.48.7\n",
      "2022-06-15 02:28:39.078435: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.48.7\n",
      "2022-06-15 02:28:39.078780: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = get_model(n_channels=len(config.INFERENCE_FEATURES))\n",
    "\n",
    "loss = losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3/3 [==============================] - 5s 433ms/step - loss: 3.8556 - accuracy: 0.0645 - val_loss: 2.6674 - val_accuracy: 0.0652\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3.3940 - accuracy: 0.1183 - val_loss: 2.6880 - val_accuracy: 0.1304\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 2.6863 - accuracy: 0.2151 - val_loss: 2.7141 - val_accuracy: 0.1522\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 2.1709 - accuracy: 0.3548 - val_loss: 2.7613 - val_accuracy: 0.1522\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.9671 - accuracy: 0.3333 - val_loss: 2.8110 - val_accuracy: 0.1522\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.7859 - accuracy: 0.3763 - val_loss: 2.8575 - val_accuracy: 0.1522\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.5254 - accuracy: 0.4516 - val_loss: 2.8757 - val_accuracy: 0.1522\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.5418 - accuracy: 0.4946 - val_loss: 2.8821 - val_accuracy: 0.1522\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.3343 - accuracy: 0.5699 - val_loss: 2.8905 - val_accuracy: 0.1522\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.1788 - accuracy: 0.6559 - val_loss: 2.9255 - val_accuracy: 0.1522\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.1244 - accuracy: 0.6667 - val_loss: 2.9650 - val_accuracy: 0.1739\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.1713 - accuracy: 0.6452 - val_loss: 3.0010 - val_accuracy: 0.1739\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.9603 - accuracy: 0.6667 - val_loss: 3.0378 - val_accuracy: 0.1739\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9165 - accuracy: 0.6237 - val_loss: 3.0815 - val_accuracy: 0.1522\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7526 - accuracy: 0.7742 - val_loss: 3.1224 - val_accuracy: 0.1739\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.8315 - accuracy: 0.7419 - val_loss: 3.1542 - val_accuracy: 0.1739\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6392 - accuracy: 0.7849 - val_loss: 3.2189 - val_accuracy: 0.1739\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7204 - accuracy: 0.7634 - val_loss: 3.2742 - val_accuracy: 0.1739\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6586 - accuracy: 0.7634 - val_loss: 3.3303 - val_accuracy: 0.1739\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5630 - accuracy: 0.8172 - val_loss: 3.3744 - val_accuracy: 0.1522\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5337 - accuracy: 0.8172 - val_loss: 3.4074 - val_accuracy: 0.1522\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4689 - accuracy: 0.8280 - val_loss: 3.4201 - val_accuracy: 0.1522\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3576 - accuracy: 0.8710 - val_loss: 3.3945 - val_accuracy: 0.1522\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4193 - accuracy: 0.8925 - val_loss: 3.3518 - val_accuracy: 0.1522\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4339 - accuracy: 0.9032 - val_loss: 3.2848 - val_accuracy: 0.2391\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3277 - accuracy: 0.8925 - val_loss: 3.2115 - val_accuracy: 0.2391\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5485 - accuracy: 0.7957 - val_loss: 3.1391 - val_accuracy: 0.2391\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3726 - accuracy: 0.8817 - val_loss: 3.0530 - val_accuracy: 0.2609\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4265 - accuracy: 0.8710 - val_loss: 2.9924 - val_accuracy: 0.2609\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3909 - accuracy: 0.8710 - val_loss: 2.9405 - val_accuracy: 0.2609\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2864 - accuracy: 0.9247 - val_loss: 2.9318 - val_accuracy: 0.2609\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2630 - accuracy: 0.9032 - val_loss: 2.9229 - val_accuracy: 0.2609\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2184 - accuracy: 0.9570 - val_loss: 2.9038 - val_accuracy: 0.2609\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3108 - accuracy: 0.8710 - val_loss: 2.9388 - val_accuracy: 0.2609\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2550 - accuracy: 0.9032 - val_loss: 2.9448 - val_accuracy: 0.2609\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2029 - accuracy: 0.9570 - val_loss: 2.9459 - val_accuracy: 0.2609\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2734 - accuracy: 0.9140 - val_loss: 2.9043 - val_accuracy: 0.2826\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2038 - accuracy: 0.9570 - val_loss: 2.8205 - val_accuracy: 0.3043\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2642 - accuracy: 0.9032 - val_loss: 2.6946 - val_accuracy: 0.3043\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2338 - accuracy: 0.9140 - val_loss: 2.6214 - val_accuracy: 0.3043\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2108 - accuracy: 0.9140 - val_loss: 2.4997 - val_accuracy: 0.3261\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2001 - accuracy: 0.9462 - val_loss: 2.3786 - val_accuracy: 0.3261\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1317 - accuracy: 0.9677 - val_loss: 2.2925 - val_accuracy: 0.3478\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1811 - accuracy: 0.9247 - val_loss: 2.2172 - val_accuracy: 0.3478\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1498 - accuracy: 0.9462 - val_loss: 2.1314 - val_accuracy: 0.3696\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2684 - accuracy: 0.9355 - val_loss: 2.0771 - val_accuracy: 0.3913\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2448 - accuracy: 0.8925 - val_loss: 2.0339 - val_accuracy: 0.3913\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1812 - accuracy: 0.9462 - val_loss: 2.0087 - val_accuracy: 0.3913\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1324 - accuracy: 0.9570 - val_loss: 1.9499 - val_accuracy: 0.4130\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1694 - accuracy: 0.9462 - val_loss: 1.9043 - val_accuracy: 0.4348\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1513 - accuracy: 0.9677 - val_loss: 1.8652 - val_accuracy: 0.4348\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2080 - accuracy: 0.9462 - val_loss: 1.8079 - val_accuracy: 0.4348\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1000 - accuracy: 0.9677 - val_loss: 1.7468 - val_accuracy: 0.4348\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1568 - accuracy: 0.9462 - val_loss: 1.6825 - val_accuracy: 0.4783\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2737 - accuracy: 0.9032 - val_loss: 1.5779 - val_accuracy: 0.4783\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1096 - accuracy: 0.9570 - val_loss: 1.4514 - val_accuracy: 0.5000\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1255 - accuracy: 0.9462 - val_loss: 1.3338 - val_accuracy: 0.5652\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1154 - accuracy: 0.9677 - val_loss: 1.2414 - val_accuracy: 0.6087\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 1.1612 - val_accuracy: 0.6087\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1125 - accuracy: 0.9677 - val_loss: 1.0844 - val_accuracy: 0.6739\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1095 - accuracy: 0.9785 - val_loss: 1.0164 - val_accuracy: 0.6522\n",
      "Epoch 62/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1666 - accuracy: 0.9355 - val_loss: 0.9929 - val_accuracy: 0.6522\n",
      "Epoch 63/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1192 - accuracy: 0.9570 - val_loss: 0.9694 - val_accuracy: 0.6957\n",
      "Epoch 64/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1543 - accuracy: 0.9570 - val_loss: 0.9829 - val_accuracy: 0.6957\n",
      "Epoch 65/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1114 - accuracy: 0.9892 - val_loss: 0.9807 - val_accuracy: 0.6739\n",
      "Epoch 66/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1203 - accuracy: 0.9462 - val_loss: 0.9644 - val_accuracy: 0.6739\n",
      "Epoch 67/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1464 - accuracy: 0.9570 - val_loss: 0.9435 - val_accuracy: 0.6957\n",
      "Epoch 68/300\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1152 - accuracy: 0.9677 - val_loss: 0.9080 - val_accuracy: 0.7174\n",
      "Epoch 69/300\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1233 - accuracy: 0.9462 - val_loss: 0.8525 - val_accuracy: 0.7174\n",
      "Epoch 70/300\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0776 - accuracy: 0.9785 - val_loss: 0.7843 - val_accuracy: 0.7174\n",
      "Epoch 71/300\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1683 - accuracy: 0.9462 - val_loss: 0.7197 - val_accuracy: 0.7391\n",
      "Epoch 72/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0841 - accuracy: 0.9785 - val_loss: 0.6576 - val_accuracy: 0.7391\n",
      "Epoch 73/300\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0840 - accuracy: 0.9677 - val_loss: 0.6078 - val_accuracy: 0.7391\n",
      "Epoch 74/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1175 - accuracy: 0.9570 - val_loss: 0.5488 - val_accuracy: 0.7609\n",
      "Epoch 75/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0860 - accuracy: 0.9677 - val_loss: 0.4746 - val_accuracy: 0.7609\n",
      "Epoch 76/300\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0811 - accuracy: 0.9892 - val_loss: 0.4228 - val_accuracy: 0.8261\n",
      "Epoch 77/300\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0709 - accuracy: 0.9785 - val_loss: 0.3960 - val_accuracy: 0.8261\n",
      "Epoch 78/300\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.8261\n",
      "Epoch 79/300\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0969 - accuracy: 0.9570 - val_loss: 0.3622 - val_accuracy: 0.8261\n",
      "Epoch 80/300\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1315 - accuracy: 0.9677 - val_loss: 0.3665 - val_accuracy: 0.8261\n",
      "Epoch 81/300\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0490 - accuracy: 0.9892 - val_loss: 0.3615 - val_accuracy: 0.8261\n",
      "Epoch 82/300\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0499 - accuracy: 0.9892 - val_loss: 0.3585 - val_accuracy: 0.8261\n",
      "Epoch 83/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.8478\n",
      "Epoch 84/300\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0794 - accuracy: 0.9677 - val_loss: 0.3364 - val_accuracy: 0.8478\n",
      "Epoch 85/300\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.8478\n",
      "Epoch 86/300\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0695 - accuracy: 0.9677 - val_loss: 0.3097 - val_accuracy: 0.8478\n",
      "Epoch 87/300\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0570 - accuracy: 0.9892 - val_loss: 0.2975 - val_accuracy: 0.8478\n",
      "Epoch 88/300\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0702 - accuracy: 0.9785 - val_loss: 0.2903 - val_accuracy: 0.8696\n",
      "Epoch 89/300\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.8696\n",
      "Epoch 90/300\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0532 - accuracy: 0.9785 - val_loss: 0.2824 - val_accuracy: 0.8696\n",
      "Epoch 91/300\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.8696\n",
      "Epoch 92/300\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0798 - accuracy: 0.9677 - val_loss: 0.2630 - val_accuracy: 0.8696\n",
      "Epoch 93/300\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0524 - accuracy: 0.9892 - val_loss: 0.2551 - val_accuracy: 0.8913\n",
      "Epoch 94/300\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0747 - accuracy: 0.9785 - val_loss: 0.2372 - val_accuracy: 0.8913\n",
      "Epoch 95/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9130\n",
      "Epoch 96/300\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9130\n",
      "Epoch 97/300\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0807 - accuracy: 0.9570 - val_loss: 0.1902 - val_accuracy: 0.9130\n",
      "Epoch 98/300\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1216 - accuracy: 0.9570 - val_loss: 0.1836 - val_accuracy: 0.9130\n",
      "Epoch 99/300\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9348\n",
      "Epoch 100/300\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9348\n",
      "Epoch 101/300\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0551 - accuracy: 0.9785 - val_loss: 0.1697 - val_accuracy: 0.9348\n",
      "Epoch 102/300\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0533 - accuracy: 0.9892 - val_loss: 0.1645 - val_accuracy: 0.9565\n",
      "Epoch 103/300\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9565\n",
      "Epoch 104/300\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9565\n",
      "Epoch 105/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0575 - accuracy: 0.9785 - val_loss: 0.1377 - val_accuracy: 0.9565\n",
      "Epoch 106/300\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9565\n",
      "Epoch 107/300\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0366 - accuracy: 0.9892 - val_loss: 0.1202 - val_accuracy: 0.9565\n",
      "Epoch 108/300\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0361 - accuracy: 0.9892 - val_loss: 0.1155 - val_accuracy: 0.9565\n",
      "Epoch 109/300\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0380 - accuracy: 0.9892 - val_loss: 0.1128 - val_accuracy: 0.9565\n",
      "Epoch 110/300\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0984 - accuracy: 0.9570 - val_loss: 0.1145 - val_accuracy: 0.9565\n",
      "Epoch 111/300\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0451 - accuracy: 0.9785 - val_loss: 0.1189 - val_accuracy: 0.9565\n",
      "Epoch 112/300\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0390 - accuracy: 0.9892 - val_loss: 0.1215 - val_accuracy: 0.9565\n",
      "Epoch 113/300\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9565\n",
      "Epoch 114/300\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9565\n",
      "Epoch 115/300\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9565\n",
      "Epoch 116/300\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0711 - accuracy: 0.9892 - val_loss: 0.1188 - val_accuracy: 0.9565\n",
      "Epoch 117/300\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0810 - accuracy: 0.9570 - val_loss: 0.1234 - val_accuracy: 0.9565\n",
      "Epoch 118/300\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0302 - accuracy: 0.9892 - val_loss: 0.1261 - val_accuracy: 0.9565\n",
      "Epoch 119/300\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9565\n",
      "Epoch 120/300\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9565\n",
      "Epoch 121/300\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0228 - accuracy: 0.9892 - val_loss: 0.1188 - val_accuracy: 0.9565\n",
      "Epoch 122/300\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0240 - accuracy: 0.9892 - val_loss: 0.1194 - val_accuracy: 0.9565\n",
      "Epoch 123/300\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0363 - accuracy: 0.9892 - val_loss: 0.1208 - val_accuracy: 0.9565\n",
      "Epoch 124/300\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9565\n",
      "Epoch 125/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1023 - accuracy: 0.9677 - val_loss: 0.1118 - val_accuracy: 0.9565\n",
      "Epoch 126/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0293 - accuracy: 0.9892 - val_loss: 0.1019 - val_accuracy: 0.9565\n",
      "Epoch 127/300\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0377 - accuracy: 0.9892 - val_loss: 0.0956 - val_accuracy: 0.9565\n",
      "Epoch 128/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0676 - accuracy: 0.9785 - val_loss: 0.0879 - val_accuracy: 0.9565\n",
      "Epoch 129/300\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0706 - accuracy: 0.9785 - val_loss: 0.0812 - val_accuracy: 0.9565\n",
      "Epoch 130/300\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9565\n",
      "Epoch 131/300\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9565\n",
      "Epoch 132/300\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0472 - accuracy: 0.9785 - val_loss: 0.0682 - val_accuracy: 0.9565\n",
      "Epoch 133/300\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0550 - accuracy: 0.9677 - val_loss: 0.0691 - val_accuracy: 0.9783\n",
      "Epoch 134/300\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0337 - accuracy: 0.9892 - val_loss: 0.0707 - val_accuracy: 0.9783\n",
      "Epoch 135/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0459 - accuracy: 0.9892 - val_loss: 0.0671 - val_accuracy: 0.9783\n",
      "Epoch 136/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0571 - accuracy: 0.9677 - val_loss: 0.0600 - val_accuracy: 0.9565\n",
      "Epoch 137/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0544 - accuracy: 0.9785 - val_loss: 0.0516 - val_accuracy: 0.9565\n",
      "Epoch 138/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0294 - accuracy: 0.9892 - val_loss: 0.0492 - val_accuracy: 0.9783\n",
      "Epoch 139/300\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9783\n",
      "Epoch 140/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0332 - accuracy: 0.9892 - val_loss: 0.0487 - val_accuracy: 0.9783\n",
      "Epoch 141/300\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0377 - accuracy: 0.9892 - val_loss: 0.0479 - val_accuracy: 0.9783\n",
      "Epoch 142/300\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9783\n",
      "Epoch 143/300\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0439 - accuracy: 0.9892 - val_loss: 0.0445 - val_accuracy: 0.9783\n",
      "Epoch 144/300\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0186 - accuracy: 0.9892 - val_loss: 0.0404 - val_accuracy: 0.9783\n",
      "Epoch 145/300\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9783\n",
      "Epoch 146/300\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0272 - accuracy: 0.9892 - val_loss: 0.0358 - val_accuracy: 0.9783\n",
      "Epoch 147/300\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0800 - accuracy: 0.9677 - val_loss: 0.0350 - val_accuracy: 0.9783\n",
      "Epoch 148/300\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0835 - accuracy: 0.9785 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0637 - accuracy: 0.9785 - val_loss: 0.0428 - val_accuracy: 0.9783\n",
      "Epoch 152/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9783\n",
      "Epoch 153/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0415 - val_accuracy: 0.9783\n",
      "Epoch 154/300\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0598 - accuracy: 0.9892 - val_loss: 0.0371 - val_accuracy: 0.9783\n",
      "Epoch 155/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0601 - accuracy: 0.9892 - val_loss: 0.0364 - val_accuracy: 0.9783\n",
      "Epoch 156/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9783\n",
      "Epoch 157/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0333 - accuracy: 0.9892 - val_loss: 0.0382 - val_accuracy: 0.9783\n",
      "Epoch 158/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9783\n",
      "Epoch 159/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0596 - accuracy: 0.9785 - val_loss: 0.0408 - val_accuracy: 0.9783\n",
      "Epoch 160/300\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9783\n",
      "Epoch 161/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.0359 - val_accuracy: 0.9783\n",
      "Epoch 162/300\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9783\n",
      "Epoch 163/300\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0216 - accuracy: 0.9892 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0250 - accuracy: 0.9892 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0157 - accuracy: 0.9892 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0433 - accuracy: 0.9785 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0447 - accuracy: 0.9785 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0224 - accuracy: 0.9892 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0408 - accuracy: 0.9892 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0398 - accuracy: 0.9785 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0289 - accuracy: 0.9892 - val_loss: 0.0321 - val_accuracy: 0.9783\n",
      "Epoch 179/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0417 - accuracy: 0.9892 - val_loss: 0.0370 - val_accuracy: 0.9783\n",
      "Epoch 180/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0197 - accuracy: 0.9892 - val_loss: 0.0416 - val_accuracy: 0.9783\n",
      "Epoch 181/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9783\n",
      "Epoch 182/300\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9783\n",
      "Epoch 183/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0744 - accuracy: 0.9785 - val_loss: 0.0511 - val_accuracy: 0.9783\n",
      "Epoch 184/300\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9565\n",
      "Epoch 185/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9565\n",
      "Epoch 186/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0663 - accuracy: 0.9677 - val_loss: 0.0889 - val_accuracy: 0.9565\n",
      "Epoch 187/300\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9565\n",
      "Epoch 188/300\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9565\n",
      "Epoch 189/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9565\n",
      "Epoch 190/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0313 - accuracy: 0.9892 - val_loss: 0.0696 - val_accuracy: 0.9565\n",
      "Epoch 191/300\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0245 - accuracy: 0.9892 - val_loss: 0.0606 - val_accuracy: 0.9565\n",
      "Epoch 192/300\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0293 - accuracy: 0.9892 - val_loss: 0.0502 - val_accuracy: 0.9565\n",
      "Epoch 193/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0377 - accuracy: 0.9892 - val_loss: 0.0397 - val_accuracy: 0.9783\n",
      "Epoch 194/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0370 - accuracy: 0.9785 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0202 - accuracy: 0.9785 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0143 - accuracy: 0.9892 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0413 - accuracy: 0.9892 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9783\n",
      "Epoch 213/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0271 - accuracy: 0.9892 - val_loss: 0.0244 - val_accuracy: 0.9783\n",
      "Epoch 214/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9783\n",
      "Epoch 215/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0348 - accuracy: 0.9785 - val_loss: 0.0220 - val_accuracy: 0.9783\n",
      "Epoch 216/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0410 - accuracy: 0.9785 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0329 - accuracy: 0.9785 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0211 - accuracy: 0.9892 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0263 - accuracy: 0.9892 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0231 - accuracy: 0.9892 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0242 - accuracy: 0.9892 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0239 - accuracy: 0.9892 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9783\n",
      "Epoch 232/300\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9783\n",
      "Epoch 233/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.0336 - val_accuracy: 0.9783\n",
      "Epoch 234/300\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0705 - accuracy: 0.9677 - val_loss: 0.0403 - val_accuracy: 0.9783\n",
      "Epoch 235/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0431 - accuracy: 0.9892 - val_loss: 0.0412 - val_accuracy: 0.9783\n",
      "Epoch 236/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0336 - accuracy: 0.9892 - val_loss: 0.0411 - val_accuracy: 0.9783\n",
      "Epoch 237/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9783\n",
      "Epoch 238/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9783\n",
      "Epoch 239/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9783\n",
      "Epoch 240/300\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9783\n",
      "Epoch 241/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0132 - accuracy: 0.9892 - val_loss: 0.0429 - val_accuracy: 0.9783\n",
      "Epoch 242/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0379 - accuracy: 0.9785 - val_loss: 0.0456 - val_accuracy: 0.9783\n",
      "Epoch 243/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9783\n",
      "Epoch 244/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9783\n",
      "Epoch 245/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9783\n",
      "Epoch 246/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9783\n",
      "Epoch 247/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0307 - accuracy: 0.9785 - val_loss: 0.0545 - val_accuracy: 0.9783\n",
      "Epoch 248/300\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9783\n",
      "Epoch 249/300\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9783\n",
      "Epoch 250/300\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9783\n",
      "Epoch 251/300\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9783\n",
      "Epoch 252/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9783\n",
      "Epoch 253/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9783\n",
      "Epoch 254/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9783\n",
      "Epoch 255/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9783\n",
      "Epoch 256/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9783\n",
      "Epoch 257/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9783\n",
      "Epoch 258/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0144 - accuracy: 0.9892 - val_loss: 0.0369 - val_accuracy: 0.9783\n",
      "Epoch 259/300\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9783\n",
      "Epoch 260/300\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9783\n",
      "Epoch 261/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0117 - accuracy: 0.9892 - val_loss: 0.0318 - val_accuracy: 0.9783\n",
      "Epoch 262/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9783\n",
      "Epoch 263/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0151 - accuracy: 0.9892 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0193 - accuracy: 0.9892 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0226 - accuracy: 0.9892 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0169 - accuracy: 0.9785 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=70,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    x=np.split(X_train, len(config.INFERENCE_FEATURES), axis=-1),\n",
    "    y=y_train,\n",
    "    validation_data=(\n",
    "        np.split(X_test, len(config.INFERENCE_FEATURES), axis=-1),\n",
    "        y_test\n",
    "    ),\n",
    "    batch_size=32,\n",
    "    epochs=300,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Computer Modern Roman\"],\n",
    "    \"font.size\": 22,\n",
    "    \"text.color\": \"#212121\",\n",
    "    \"axes.edgecolor\": \"#212121\",\n",
    "    \"xtick.color\": \"#212121\",\n",
    "    \"ytick.color\": \"#212121\",\n",
    "    \"axes.labelcolor\": \"#212121\",\n",
    "    'legend.frameon': False,\n",
    "})\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.gca()\n",
    "ax.plot(history.history[\"loss\"], \"-\", color=\"#212121\", label=\"Train Loss\")\n",
    "ax.plot(history.history[\"val_loss\"], \"--\", color=\"#212121\", label=\"Validation Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.title(\"Learning Curves\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 72). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../model/stack_cnn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../model/stack_cnn/assets\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, \"../../model/scaler.joblib\")\n",
    "model.save(\"../../model/stack_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f0f52ed645d8567bae68a8c372449e0a23f49f10e778396b1f58fd2946c160c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
