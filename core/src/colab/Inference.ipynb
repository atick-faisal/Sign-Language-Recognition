{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Sign-Language-Recognition/blob/main/core/src/colab/Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JmRmSvWP8Ma-",
        "outputId": "c2c60e07-88bb-4406-a082-83d26d748915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rich\n",
        "!gdown \"1CACL0ogqPC87Tsqo3qxX31ve04_Cxdjf\"\n",
        "!tar -xf raw.tar.xz\n",
        "!git clone https://github.com/atick-faisal/Sign-Language-Recognition.git"
      ],
      "metadata": {
        "id": "V-n5fxnqAdnr",
        "outputId": "23f1eef3-c33e-456c-c7e4-9f921d6d96bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rich\n",
            "  Downloading rich-12.4.4-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from rich) (4.1.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: commonmark, rich\n",
            "Successfully installed commonmark-0.9.1 rich-12.4.4\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CACL0ogqPC87Tsqo3qxX31ve04_Cxdjf\n",
            "To: /content/raw.tar.xz\n",
            "100% 21.6M/21.6M [00:00<00:00, 25.2MB/s]\n",
            "Cloning into 'Sign-Language-Recognition'...\n",
            "remote: Enumerating objects: 1112, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 1112 (delta 77), reused 50 (delta 28), pack-reused 989\u001b[K\n",
            "Receiving objects: 100% (1112/1112), 4.25 MiB | 18.21 MiB/s, done.\n",
            "Resolving deltas: 100% (661/661), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Sign-Language-Recognition/core/src/train_tf.py \\\n",
        "        --exp_name \"stack_cnn_u007_lw2\" \\\n",
        "        --data_dir \"raw\" \\\n",
        "        --model_dir \"/content/drive/MyDrive/Research/Leap Motion Controller/Models\""
      ],
      "metadata": {
        "id": "LeMkJoC98cym",
        "outputId": "179ab652-8cdf-45c3-9bc7-c87ecc6a6cf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------\n",
            "Generating Dataset\n",
            "----------------------------------------------------------------------\n",
            "\u001b[2K[ 1167/ 1178] processing files:  \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 99%\u001b[0m \u001b[36m0:00:09\u001b[0m\n",
            "\u001b[?25htcmalloc: large alloc 1379639296 bytes == 0x662d8000 @  0x7f8ac98281e7 0x7f8ac5db90ce 0x7f8ac5e15715 0x7f8ac5e15d1b 0x7f8ac5eb6333 0x5936cc 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f8ac9425c87 0x5b621a\n",
            "----------------------------------------------------------------------\n",
            "Train Features Shape:  (5988, 150, 1)\n",
            "Train Images Shape:  (5988, 160, 160, 3)\n",
            "Test Features Shape:  (161, 150, 1)\n",
            "Test Images Shape:  (161, 160, 160, 3)\n",
            "Train Labels Shape:  (5988,)\n",
            "Test Labels Shape:  (161,)\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Training Model ... \n",
            "----------------------------------------------------------------------\n",
            "Epoch 1/300\n",
            "94/94 [==============================] - 25s 159ms/step - loss: 1.9036 - accuracy: 0.3829 - val_loss: 1.3853 - val_accuracy: 0.6211\n",
            "Epoch 2/300\n",
            "94/94 [==============================] - 11s 121ms/step - loss: 0.7135 - accuracy: 0.7622 - val_loss: 0.6116 - val_accuracy: 0.8261\n",
            "Epoch 3/300\n",
            "94/94 [==============================] - 11s 121ms/step - loss: 0.4878 - accuracy: 0.8353 - val_loss: 0.3975 - val_accuracy: 0.8571\n",
            "Epoch 4/300\n",
            "94/94 [==============================] - 11s 122ms/step - loss: 0.3976 - accuracy: 0.8634 - val_loss: 0.3250 - val_accuracy: 0.8571\n",
            "Epoch 5/300\n",
            "94/94 [==============================] - 11s 122ms/step - loss: 0.3229 - accuracy: 0.8898 - val_loss: 0.2659 - val_accuracy: 0.8758\n",
            "Epoch 6/300\n",
            "94/94 [==============================] - 12s 123ms/step - loss: 0.3061 - accuracy: 0.8901 - val_loss: 0.2644 - val_accuracy: 0.9255\n",
            "Epoch 7/300\n",
            "94/94 [==============================] - 12s 123ms/step - loss: 0.2728 - accuracy: 0.9025 - val_loss: 0.2979 - val_accuracy: 0.8634\n",
            "Epoch 8/300\n",
            "94/94 [==============================] - 12s 124ms/step - loss: 0.2537 - accuracy: 0.9110 - val_loss: 0.2552 - val_accuracy: 0.8820\n",
            "Epoch 9/300\n",
            "94/94 [==============================] - 12s 124ms/step - loss: 0.2588 - accuracy: 0.9081 - val_loss: 0.3204 - val_accuracy: 0.8571\n",
            "Epoch 10/300\n",
            "94/94 [==============================] - 12s 124ms/step - loss: 0.2319 - accuracy: 0.9172 - val_loss: 0.3349 - val_accuracy: 0.8447\n",
            "Epoch 11/300\n",
            "94/94 [==============================] - 12s 127ms/step - loss: 0.2233 - accuracy: 0.9213 - val_loss: 0.2516 - val_accuracy: 0.8696\n",
            "Epoch 12/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.2051 - accuracy: 0.9237 - val_loss: 0.2866 - val_accuracy: 0.8696\n",
            "Epoch 13/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1974 - accuracy: 0.9284 - val_loss: 0.3097 - val_accuracy: 0.8634\n",
            "Epoch 14/300\n",
            "94/94 [==============================] - 12s 126ms/step - loss: 0.1998 - accuracy: 0.9292 - val_loss: 0.2346 - val_accuracy: 0.9006\n",
            "Epoch 15/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1855 - accuracy: 0.9324 - val_loss: 0.2950 - val_accuracy: 0.8634\n",
            "Epoch 16/300\n",
            "94/94 [==============================] - 12s 124ms/step - loss: 0.1893 - accuracy: 0.9350 - val_loss: 0.2537 - val_accuracy: 0.8758\n",
            "Epoch 17/300\n",
            "94/94 [==============================] - 12s 124ms/step - loss: 0.1731 - accuracy: 0.9324 - val_loss: 0.2567 - val_accuracy: 0.8696\n",
            "Epoch 18/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1736 - accuracy: 0.9367 - val_loss: 0.2529 - val_accuracy: 0.8758\n",
            "Epoch 19/300\n",
            "94/94 [==============================] - 12s 127ms/step - loss: 0.1713 - accuracy: 0.9362 - val_loss: 0.2896 - val_accuracy: 0.8634\n",
            "Epoch 20/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1605 - accuracy: 0.9410 - val_loss: 0.2968 - val_accuracy: 0.8509\n",
            "Epoch 21/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1668 - accuracy: 0.9384 - val_loss: 0.3215 - val_accuracy: 0.8571\n",
            "Epoch 22/300\n",
            "94/94 [==============================] - 12s 124ms/step - loss: 0.1643 - accuracy: 0.9382 - val_loss: 0.3802 - val_accuracy: 0.8447\n",
            "Epoch 23/300\n",
            "94/94 [==============================] - 12s 124ms/step - loss: 0.1629 - accuracy: 0.9404 - val_loss: 0.2731 - val_accuracy: 0.8696\n",
            "Epoch 24/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1578 - accuracy: 0.9439 - val_loss: 0.2229 - val_accuracy: 0.9068\n",
            "Epoch 25/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1540 - accuracy: 0.9446 - val_loss: 0.2325 - val_accuracy: 0.8758\n",
            "Epoch 26/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1496 - accuracy: 0.9454 - val_loss: 0.2946 - val_accuracy: 0.8634\n",
            "Epoch 27/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1421 - accuracy: 0.9474 - val_loss: 0.2591 - val_accuracy: 0.8820\n",
            "Epoch 28/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1464 - accuracy: 0.9456 - val_loss: 0.2580 - val_accuracy: 0.8882\n",
            "Epoch 29/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1421 - accuracy: 0.9482 - val_loss: 0.2883 - val_accuracy: 0.8696\n",
            "Epoch 30/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1484 - accuracy: 0.9466 - val_loss: 0.3005 - val_accuracy: 0.8696\n",
            "Epoch 31/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1465 - accuracy: 0.9479 - val_loss: 0.4085 - val_accuracy: 0.8447\n",
            "Epoch 32/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1439 - accuracy: 0.9464 - val_loss: 0.2657 - val_accuracy: 0.8696\n",
            "Epoch 33/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1397 - accuracy: 0.9487 - val_loss: 0.2849 - val_accuracy: 0.8758\n",
            "Epoch 34/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1366 - accuracy: 0.9474 - val_loss: 0.2237 - val_accuracy: 0.8882\n",
            "Epoch 35/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1430 - accuracy: 0.9452 - val_loss: 0.2792 - val_accuracy: 0.8820\n",
            "Epoch 36/300\n",
            "94/94 [==============================] - 12s 128ms/step - loss: 0.1404 - accuracy: 0.9472 - val_loss: 0.2079 - val_accuracy: 0.9006\n",
            "Epoch 37/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1324 - accuracy: 0.9501 - val_loss: 0.2659 - val_accuracy: 0.8758\n",
            "Epoch 38/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1297 - accuracy: 0.9521 - val_loss: 0.3142 - val_accuracy: 0.8820\n",
            "Epoch 39/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1326 - accuracy: 0.9526 - val_loss: 0.2987 - val_accuracy: 0.9006\n",
            "Epoch 40/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1294 - accuracy: 0.9509 - val_loss: 0.3441 - val_accuracy: 0.8696\n",
            "Epoch 41/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1308 - accuracy: 0.9506 - val_loss: 0.2751 - val_accuracy: 0.8944\n",
            "Epoch 42/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1237 - accuracy: 0.9524 - val_loss: 0.2560 - val_accuracy: 0.8944\n",
            "Epoch 43/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1323 - accuracy: 0.9502 - val_loss: 0.4068 - val_accuracy: 0.8820\n",
            "Epoch 44/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1310 - accuracy: 0.9524 - val_loss: 0.4491 - val_accuracy: 0.8696\n",
            "Epoch 45/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1354 - accuracy: 0.9484 - val_loss: 0.4457 - val_accuracy: 0.8634\n",
            "Epoch 46/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1248 - accuracy: 0.9536 - val_loss: 0.4425 - val_accuracy: 0.8634\n",
            "Epoch 47/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1254 - accuracy: 0.9544 - val_loss: 0.3709 - val_accuracy: 0.8696\n",
            "Epoch 48/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1242 - accuracy: 0.9524 - val_loss: 0.2301 - val_accuracy: 0.9068\n",
            "Epoch 49/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1304 - accuracy: 0.9507 - val_loss: 0.3407 - val_accuracy: 0.8758\n",
            "Epoch 50/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1301 - accuracy: 0.9519 - val_loss: 0.3678 - val_accuracy: 0.8634\n",
            "Epoch 51/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1268 - accuracy: 0.9537 - val_loss: 0.2689 - val_accuracy: 0.8882\n",
            "Epoch 52/300\n",
            "94/94 [==============================] - 12s 126ms/step - loss: 0.1306 - accuracy: 0.9514 - val_loss: 0.1859 - val_accuracy: 0.9193\n",
            "Epoch 53/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1243 - accuracy: 0.9514 - val_loss: 0.2664 - val_accuracy: 0.8696\n",
            "Epoch 54/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1242 - accuracy: 0.9532 - val_loss: 0.2958 - val_accuracy: 0.8820\n",
            "Epoch 55/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1262 - accuracy: 0.9534 - val_loss: 0.3799 - val_accuracy: 0.8696\n",
            "Epoch 56/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1218 - accuracy: 0.9537 - val_loss: 0.3060 - val_accuracy: 0.8696\n",
            "Epoch 57/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1287 - accuracy: 0.9516 - val_loss: 0.4155 - val_accuracy: 0.8571\n",
            "Epoch 58/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1229 - accuracy: 0.9531 - val_loss: 0.3075 - val_accuracy: 0.8944\n",
            "Epoch 59/300\n",
            "94/94 [==============================] - 12s 126ms/step - loss: 0.1206 - accuracy: 0.9554 - val_loss: 0.4169 - val_accuracy: 0.8758\n",
            "Epoch 60/300\n",
            "94/94 [==============================] - 12s 126ms/step - loss: 0.1225 - accuracy: 0.9536 - val_loss: 0.2295 - val_accuracy: 0.8882\n",
            "Epoch 61/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1221 - accuracy: 0.9536 - val_loss: 0.3928 - val_accuracy: 0.8634\n",
            "Epoch 62/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1211 - accuracy: 0.9544 - val_loss: 0.3286 - val_accuracy: 0.8882\n",
            "Epoch 63/300\n",
            "94/94 [==============================] - 12s 124ms/step - loss: 0.1230 - accuracy: 0.9546 - val_loss: 0.4554 - val_accuracy: 0.8509\n",
            "Epoch 64/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1220 - accuracy: 0.9531 - val_loss: 0.2268 - val_accuracy: 0.9006\n",
            "Epoch 65/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1235 - accuracy: 0.9531 - val_loss: 0.2451 - val_accuracy: 0.8820\n",
            "Epoch 66/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1200 - accuracy: 0.9529 - val_loss: 0.3985 - val_accuracy: 0.8696\n",
            "Epoch 67/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1235 - accuracy: 0.9537 - val_loss: 0.2239 - val_accuracy: 0.9006\n",
            "Epoch 68/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1231 - accuracy: 0.9534 - val_loss: 0.3030 - val_accuracy: 0.8944\n",
            "Epoch 69/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1164 - accuracy: 0.9549 - val_loss: 0.3643 - val_accuracy: 0.8944\n",
            "Epoch 70/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1211 - accuracy: 0.9541 - val_loss: 0.3925 - val_accuracy: 0.8634\n",
            "Epoch 71/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1198 - accuracy: 0.9542 - val_loss: 0.2641 - val_accuracy: 0.9006\n",
            "Epoch 72/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1199 - accuracy: 0.9552 - val_loss: 0.3119 - val_accuracy: 0.8882\n",
            "Epoch 73/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1218 - accuracy: 0.9542 - val_loss: 0.3418 - val_accuracy: 0.8758\n",
            "Epoch 74/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1189 - accuracy: 0.9539 - val_loss: 0.2883 - val_accuracy: 0.8820\n",
            "Epoch 75/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1227 - accuracy: 0.9547 - val_loss: 0.2846 - val_accuracy: 0.8944\n",
            "Epoch 76/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1137 - accuracy: 0.9567 - val_loss: 0.2746 - val_accuracy: 0.8882\n",
            "Epoch 77/300\n",
            "94/94 [==============================] - 12s 124ms/step - loss: 0.1209 - accuracy: 0.9552 - val_loss: 0.3384 - val_accuracy: 0.8758\n",
            "Epoch 78/300\n",
            "94/94 [==============================] - 12s 124ms/step - loss: 0.1225 - accuracy: 0.9536 - val_loss: 0.2852 - val_accuracy: 0.9006\n",
            "Epoch 79/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1236 - accuracy: 0.9547 - val_loss: 0.3115 - val_accuracy: 0.8820\n",
            "Epoch 80/300\n",
            "94/94 [==============================] - 12s 128ms/step - loss: 0.1204 - accuracy: 0.9552 - val_loss: 0.5092 - val_accuracy: 0.8571\n",
            "Epoch 81/300\n",
            "94/94 [==============================] - 12s 125ms/step - loss: 0.1239 - accuracy: 0.9551 - val_loss: 0.3496 - val_accuracy: 0.8696\n",
            "Epoch 82/300\n",
            "94/94 [==============================] - 12s 126ms/step - loss: 0.1193 - accuracy: 0.9536 - val_loss: 0.3908 - val_accuracy: 0.8820\n",
            "----------------------------------------------------------------------\n",
            "Metrics \n",
            "----------------------------------------------------------------------\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.1859 - accuracy: 0.9193\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.58      0.74        12\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       1.00      0.67      0.80        12\n",
            "           4       1.00      1.00      1.00        12\n",
            "           5       1.00      1.00      1.00        12\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        12\n",
            "           8       0.52      1.00      0.69        12\n",
            "           9       1.00      0.92      0.96        12\n",
            "          10       0.85      0.92      0.88        12\n",
            "          11       1.00      1.00      1.00         5\n",
            "          12       1.00      1.00      1.00        12\n",
            "          13       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.92       161\n",
            "   macro avg       0.95      0.92      0.93       161\n",
            "weighted avg       0.95      0.92      0.92       161\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Saving Results ... \n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Inference.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}