{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Sign-Language-Recognition/blob/main/core/src/colab/Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JmRmSvWP8Ma-",
        "outputId": "3b51a687-b891-4379-97f9-9486066dc350",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rich\n",
        "!gdown \"1CACL0ogqPC87Tsqo3qxX31ve04_Cxdjf\"\n",
        "!tar -xf raw.tar.xz\n",
        "!git clone https://github.com/atick-faisal/Sign-Language-Recognition.git"
      ],
      "metadata": {
        "id": "V-n5fxnqAdnr",
        "outputId": "2de07062-c49d-4ecc-ae8e-ddb226ba617c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rich\n",
            "  Downloading rich-12.4.4-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 32.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from rich) (4.1.1)\n",
            "Installing collected packages: commonmark, rich\n",
            "Successfully installed commonmark-0.9.1 rich-12.4.4\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CACL0ogqPC87Tsqo3qxX31ve04_Cxdjf\n",
            "To: /content/raw.tar.xz\n",
            "100% 21.6M/21.6M [00:00<00:00, 35.4MB/s]\n",
            "Cloning into 'Sign-Language-Recognition'...\n",
            "remote: Enumerating objects: 979, done.\u001b[K\n",
            "remote: Counting objects: 100% (495/495), done.\u001b[K\n",
            "remote: Compressing objects: 100% (325/325), done.\u001b[K\n",
            "remote: Total 979 (delta 272), reused 353 (delta 152), pack-reused 484\u001b[K\n",
            "Receiving objects: 100% (979/979), 4.22 MiB | 18.24 MiB/s, done.\n",
            "Resolving deltas: 100% (555/555), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Sign-Language-Recognition/core/src/train_tf.py \\\n",
        "        --exp_name \"stack_cnn_160x160_lw2\" \\\n",
        "        --data_dir \"raw\" \\\n",
        "        --model_dir \"/content/drive/MyDrive/Research/Leap Motion Controller/Models\""
      ],
      "metadata": {
        "id": "LeMkJoC98cym",
        "outputId": "ec190b84-dd34-4aa9-ff68-ec225c75132f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------\n",
            "Generating Dataset\n",
            "----------------------------------------------------------------------\n",
            "\u001b[2K[ 1167/ 1178] processing files:  \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 99%\u001b[0m \u001b[36m0:00:07\u001b[0m\n",
            "\u001b[?25htcmalloc: large alloc 1298079744 bytes == 0x621dc000 @  0x7f7fd01a41e7 0x7f7fcc7350ce 0x7f7fcc791715 0x7f7fcc791d1b 0x7f7fcc832333 0x5936cc 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f7fcfda1c87 0x5b621a\n",
            "----------------------------------------------------------------------\n",
            "Train Features Shape:  (5634, 150, 1)\n",
            "Train Images Shape:  (5634, 160, 160, 3)\n",
            "Test Features Shape:  (220, 150, 1)\n",
            "Test Images Shape:  (220, 160, 160, 3)\n",
            "Train Labels Shape:  (5634,)\n",
            "Test Labels Shape:  (220,)\n",
            "----------------------------------------------------------------------\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n",
            "----------------------------------------------------------------------\n",
            "Training Model ... \n",
            "----------------------------------------------------------------------\n",
            "Epoch 1/300\n",
            "177/177 [==============================] - 36s 89ms/step - loss: 1.6299 - accuracy: 0.4764 - val_loss: 0.5153 - val_accuracy: 0.9136\n",
            "Epoch 2/300\n",
            "177/177 [==============================] - 12s 70ms/step - loss: 0.6232 - accuracy: 0.7953 - val_loss: 0.2140 - val_accuracy: 0.9500\n",
            "Epoch 3/300\n",
            "177/177 [==============================] - 12s 70ms/step - loss: 0.4278 - accuracy: 0.8587 - val_loss: 0.1698 - val_accuracy: 0.9545\n",
            "Epoch 4/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.3547 - accuracy: 0.8825 - val_loss: 0.1626 - val_accuracy: 0.9545\n",
            "Epoch 5/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.3133 - accuracy: 0.8940 - val_loss: 0.1294 - val_accuracy: 0.9636\n",
            "Epoch 6/300\n",
            "177/177 [==============================] - 12s 70ms/step - loss: 0.2613 - accuracy: 0.9070 - val_loss: 0.1414 - val_accuracy: 0.9591\n",
            "Epoch 7/300\n",
            "177/177 [==============================] - 12s 70ms/step - loss: 0.2383 - accuracy: 0.9178 - val_loss: 0.1507 - val_accuracy: 0.9591\n",
            "Epoch 8/300\n",
            "177/177 [==============================] - 12s 70ms/step - loss: 0.2073 - accuracy: 0.9272 - val_loss: 0.1264 - val_accuracy: 0.9682\n",
            "Epoch 9/300\n",
            "177/177 [==============================] - 12s 70ms/step - loss: 0.2048 - accuracy: 0.9265 - val_loss: 0.1337 - val_accuracy: 0.9591\n",
            "Epoch 10/300\n",
            "177/177 [==============================] - 12s 70ms/step - loss: 0.1764 - accuracy: 0.9329 - val_loss: 0.1387 - val_accuracy: 0.9773\n",
            "Epoch 11/300\n",
            "177/177 [==============================] - 12s 70ms/step - loss: 0.1729 - accuracy: 0.9370 - val_loss: 0.1373 - val_accuracy: 0.9773\n",
            "Epoch 12/300\n",
            "177/177 [==============================] - 12s 71ms/step - loss: 0.1724 - accuracy: 0.9373 - val_loss: 0.1377 - val_accuracy: 0.9455\n",
            "Epoch 13/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.1600 - accuracy: 0.9366 - val_loss: 0.1310 - val_accuracy: 0.9727\n",
            "Epoch 14/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.1595 - accuracy: 0.9425 - val_loss: 0.1512 - val_accuracy: 0.9682\n",
            "Epoch 15/300\n",
            "177/177 [==============================] - 12s 70ms/step - loss: 0.1373 - accuracy: 0.9489 - val_loss: 0.1364 - val_accuracy: 0.9727\n",
            "Epoch 16/300\n",
            "177/177 [==============================] - 12s 71ms/step - loss: 0.1635 - accuracy: 0.9420 - val_loss: 0.1376 - val_accuracy: 0.9727\n",
            "Epoch 17/300\n",
            "177/177 [==============================] - 12s 70ms/step - loss: 0.1356 - accuracy: 0.9489 - val_loss: 0.1415 - val_accuracy: 0.9727\n",
            "Epoch 18/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.1218 - accuracy: 0.9570 - val_loss: 0.1321 - val_accuracy: 0.9636\n",
            "Epoch 19/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.1195 - accuracy: 0.9567 - val_loss: 0.1139 - val_accuracy: 0.9773\n",
            "Epoch 20/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.1167 - accuracy: 0.9567 - val_loss: 0.1148 - val_accuracy: 0.9727\n",
            "Epoch 21/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.1097 - accuracy: 0.9581 - val_loss: 0.1260 - val_accuracy: 0.9773\n",
            "Epoch 22/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.1222 - accuracy: 0.9570 - val_loss: 0.1679 - val_accuracy: 0.9591\n",
            "Epoch 23/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.1081 - accuracy: 0.9604 - val_loss: 0.1489 - val_accuracy: 0.9727\n",
            "Epoch 24/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.1081 - accuracy: 0.9588 - val_loss: 0.1352 - val_accuracy: 0.9818\n",
            "Epoch 25/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.0983 - accuracy: 0.9638 - val_loss: 0.1318 - val_accuracy: 0.9727\n",
            "Epoch 26/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.1172 - accuracy: 0.9569 - val_loss: 0.1486 - val_accuracy: 0.9727\n",
            "Epoch 27/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0992 - accuracy: 0.9613 - val_loss: 0.1641 - val_accuracy: 0.9591\n",
            "Epoch 28/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.1014 - accuracy: 0.9618 - val_loss: 0.1526 - val_accuracy: 0.9818\n",
            "Epoch 29/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.1009 - accuracy: 0.9618 - val_loss: 0.1313 - val_accuracy: 0.9773\n",
            "Epoch 30/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0928 - accuracy: 0.9670 - val_loss: 0.1504 - val_accuracy: 0.9773\n",
            "Epoch 31/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0979 - accuracy: 0.9636 - val_loss: 0.1441 - val_accuracy: 0.9864\n",
            "Epoch 32/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0849 - accuracy: 0.9668 - val_loss: 0.1432 - val_accuracy: 0.9818\n",
            "Epoch 33/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.1113 - accuracy: 0.9608 - val_loss: 0.1772 - val_accuracy: 0.9773\n",
            "Epoch 34/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.1069 - accuracy: 0.9631 - val_loss: 0.1523 - val_accuracy: 0.9773\n",
            "Epoch 35/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0995 - accuracy: 0.9636 - val_loss: 0.1330 - val_accuracy: 0.9773\n",
            "Epoch 36/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.0840 - accuracy: 0.9684 - val_loss: 0.1403 - val_accuracy: 0.9773\n",
            "Epoch 37/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0880 - accuracy: 0.9659 - val_loss: 0.1268 - val_accuracy: 0.9773\n",
            "Epoch 38/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0846 - accuracy: 0.9684 - val_loss: 0.1366 - val_accuracy: 0.9864\n",
            "Epoch 39/300\n",
            "177/177 [==============================] - 13s 71ms/step - loss: 0.0851 - accuracy: 0.9693 - val_loss: 0.1928 - val_accuracy: 0.9727\n",
            "Epoch 40/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0739 - accuracy: 0.9746 - val_loss: 0.1455 - val_accuracy: 0.9773\n",
            "Epoch 41/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0735 - accuracy: 0.9727 - val_loss: 0.1546 - val_accuracy: 0.9773\n",
            "Epoch 42/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0838 - accuracy: 0.9698 - val_loss: 0.1423 - val_accuracy: 0.9773\n",
            "Epoch 43/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0747 - accuracy: 0.9739 - val_loss: 0.1598 - val_accuracy: 0.9773\n",
            "Epoch 44/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0736 - accuracy: 0.9696 - val_loss: 0.1768 - val_accuracy: 0.9773\n",
            "Epoch 45/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0740 - accuracy: 0.9714 - val_loss: 0.1731 - val_accuracy: 0.9773\n",
            "Epoch 46/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0839 - accuracy: 0.9709 - val_loss: 0.1755 - val_accuracy: 0.9773\n",
            "Epoch 47/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0694 - accuracy: 0.9743 - val_loss: 0.1828 - val_accuracy: 0.9773\n",
            "Epoch 48/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0684 - accuracy: 0.9739 - val_loss: 0.1598 - val_accuracy: 0.9818\n",
            "Epoch 49/300\n",
            "177/177 [==============================] - 13s 72ms/step - loss: 0.0838 - accuracy: 0.9709 - val_loss: 0.1551 - val_accuracy: 0.9773\n",
            "----------------------------------------------------------------------\n",
            "Metrics \n",
            "----------------------------------------------------------------------\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 0.1139 - accuracy: 0.9773\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.90      0.93        21\n",
            "           1       1.00      1.00      1.00        15\n",
            "           2       0.94      0.94      0.94        17\n",
            "           3       1.00      1.00      1.00        18\n",
            "           4       0.95      1.00      0.97        19\n",
            "           5       1.00      0.92      0.96        12\n",
            "           6       1.00      0.94      0.97        17\n",
            "           7       1.00      1.00      1.00        16\n",
            "           8       1.00      1.00      1.00        13\n",
            "           9       1.00      1.00      1.00        17\n",
            "          10       0.83      1.00      0.91        10\n",
            "          11       1.00      1.00      1.00        17\n",
            "          12       1.00      1.00      1.00        13\n",
            "          13       1.00      1.00      1.00        15\n",
            "\n",
            "    accuracy                           0.98       220\n",
            "   macro avg       0.98      0.98      0.98       220\n",
            "weighted avg       0.98      0.98      0.98       220\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Saving Results ... \n",
            "----------------------------------------------------------------------\n",
            "No Previous Accuracy Found!\n",
            "Traceback (most recent call last):\n",
            "  File \"Sign-Language-Recognition/core/src/train_tf.py\", line 138, in <module>\n",
            "    main(exp_name, data_dir, model_dir)\n",
            "  File \"Sign-Language-Recognition/core/src/train_tf.py\", line 122, in main\n",
            "    model_dir, f\"{exp_name}_config.joblib\"))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/numpy_pickle.py\", line 482, in dump\n",
            "    NumpyPickler(f, protocol=protocol).dump(value)\n",
            "  File \"/usr/lib/python3.7/pickle.py\", line 437, in dump\n",
            "    self.save(obj)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/numpy_pickle.py\", line 284, in save\n",
            "    return Pickler.save(self, obj)\n",
            "  File \"/usr/lib/python3.7/pickle.py\", line 524, in save\n",
            "    rv = reduce(self.proto)\n",
            "TypeError: can't pickle module objects\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Inference.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}