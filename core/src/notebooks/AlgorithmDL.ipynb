{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import resample\n",
    "from scipy.stats import mode\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data/dataset/raw/\"\n",
    "subjects = os.listdir(data_dir)\n",
    "gestures = config.GESTURES\n",
    "learning_rate = 3e-4\n",
    "\n",
    "test_subject = \"007\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rpx</th>\n",
       "      <th>rpy</th>\n",
       "      <th>rpz</th>\n",
       "      <th>lpx</th>\n",
       "      <th>lpy</th>\n",
       "      <th>lpz</th>\n",
       "      <th>rf0x</th>\n",
       "      <th>rf0y</th>\n",
       "      <th>rf0z</th>\n",
       "      <th>...</th>\n",
       "      <th>lf4x</th>\n",
       "      <th>lf4y</th>\n",
       "      <th>lf4z</th>\n",
       "      <th>drf0x</th>\n",
       "      <th>drf0y</th>\n",
       "      <th>drf0z</th>\n",
       "      <th>drf1x</th>\n",
       "      <th>drf1y</th>\n",
       "      <th>drf1z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-6.608069</td>\n",
       "      <td>59.958247</td>\n",
       "      <td>19.360842</td>\n",
       "      <td>-9.343826</td>\n",
       "      <td>68.774876</td>\n",
       "      <td>20.247514</td>\n",
       "      <td>-6.508840</td>\n",
       "      <td>63.852178</td>\n",
       "      <td>5.695187</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.814304</td>\n",
       "      <td>60.980294</td>\n",
       "      <td>2.524857</td>\n",
       "      <td>0.099229</td>\n",
       "      <td>3.893931</td>\n",
       "      <td>-13.665656</td>\n",
       "      <td>-1.438373</td>\n",
       "      <td>3.969895</td>\n",
       "      <td>-50.970593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-11.372660</td>\n",
       "      <td>102.337328</td>\n",
       "      <td>34.634097</td>\n",
       "      <td>-16.858438</td>\n",
       "      <td>124.085888</td>\n",
       "      <td>36.531230</td>\n",
       "      <td>-92.139376</td>\n",
       "      <td>104.732563</td>\n",
       "      <td>12.983442</td>\n",
       "      <td>...</td>\n",
       "      <td>-75.442740</td>\n",
       "      <td>110.022647</td>\n",
       "      <td>4.555429</td>\n",
       "      <td>-80.766716</td>\n",
       "      <td>2.395235</td>\n",
       "      <td>-21.650654</td>\n",
       "      <td>-24.435209</td>\n",
       "      <td>23.184260</td>\n",
       "      <td>-90.575245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-11.398428</td>\n",
       "      <td>102.826734</td>\n",
       "      <td>34.457183</td>\n",
       "      <td>-16.759562</td>\n",
       "      <td>123.358112</td>\n",
       "      <td>36.316970</td>\n",
       "      <td>-76.298842</td>\n",
       "      <td>106.069364</td>\n",
       "      <td>12.435599</td>\n",
       "      <td>...</td>\n",
       "      <td>-75.000260</td>\n",
       "      <td>109.377353</td>\n",
       "      <td>4.528711</td>\n",
       "      <td>-64.900413</td>\n",
       "      <td>3.242630</td>\n",
       "      <td>-22.021584</td>\n",
       "      <td>-20.133036</td>\n",
       "      <td>19.964372</td>\n",
       "      <td>-90.307978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-11.409317</td>\n",
       "      <td>102.759617</td>\n",
       "      <td>34.605644</td>\n",
       "      <td>-16.858438</td>\n",
       "      <td>124.085888</td>\n",
       "      <td>36.531230</td>\n",
       "      <td>-85.918522</td>\n",
       "      <td>105.472387</td>\n",
       "      <td>12.853721</td>\n",
       "      <td>...</td>\n",
       "      <td>-75.442740</td>\n",
       "      <td>110.022647</td>\n",
       "      <td>4.555429</td>\n",
       "      <td>-74.509205</td>\n",
       "      <td>2.712770</td>\n",
       "      <td>-21.751923</td>\n",
       "      <td>-22.770234</td>\n",
       "      <td>21.873154</td>\n",
       "      <td>-90.686315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-11.357979</td>\n",
       "      <td>102.578288</td>\n",
       "      <td>34.388012</td>\n",
       "      <td>-16.759562</td>\n",
       "      <td>123.358112</td>\n",
       "      <td>36.316970</td>\n",
       "      <td>-79.137049</td>\n",
       "      <td>105.614143</td>\n",
       "      <td>12.572882</td>\n",
       "      <td>...</td>\n",
       "      <td>-75.000260</td>\n",
       "      <td>109.377353</td>\n",
       "      <td>4.528711</td>\n",
       "      <td>-67.779070</td>\n",
       "      <td>3.035854</td>\n",
       "      <td>-21.815130</td>\n",
       "      <td>-20.928603</td>\n",
       "      <td>20.470597</td>\n",
       "      <td>-90.263742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149845</th>\n",
       "      <td>145</td>\n",
       "      <td>-18.958171</td>\n",
       "      <td>154.817277</td>\n",
       "      <td>75.649850</td>\n",
       "      <td>-25.858632</td>\n",
       "      <td>169.038715</td>\n",
       "      <td>59.970166</td>\n",
       "      <td>-113.173476</td>\n",
       "      <td>154.421146</td>\n",
       "      <td>69.900119</td>\n",
       "      <td>...</td>\n",
       "      <td>-76.200763</td>\n",
       "      <td>145.314141</td>\n",
       "      <td>13.813910</td>\n",
       "      <td>-94.215305</td>\n",
       "      <td>-0.396131</td>\n",
       "      <td>-5.749732</td>\n",
       "      <td>-26.478814</td>\n",
       "      <td>10.788288</td>\n",
       "      <td>-101.673058</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149846</th>\n",
       "      <td>146</td>\n",
       "      <td>-18.299899</td>\n",
       "      <td>152.024028</td>\n",
       "      <td>74.276472</td>\n",
       "      <td>-25.706968</td>\n",
       "      <td>168.047285</td>\n",
       "      <td>59.618434</td>\n",
       "      <td>-112.106843</td>\n",
       "      <td>151.445335</td>\n",
       "      <td>68.398810</td>\n",
       "      <td>...</td>\n",
       "      <td>-75.753837</td>\n",
       "      <td>144.461859</td>\n",
       "      <td>13.732890</td>\n",
       "      <td>-93.806944</td>\n",
       "      <td>-0.578693</td>\n",
       "      <td>-5.877662</td>\n",
       "      <td>-25.733438</td>\n",
       "      <td>9.947693</td>\n",
       "      <td>-100.753324</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149847</th>\n",
       "      <td>147</td>\n",
       "      <td>-18.774816</td>\n",
       "      <td>155.144610</td>\n",
       "      <td>75.676438</td>\n",
       "      <td>-25.858632</td>\n",
       "      <td>169.038715</td>\n",
       "      <td>59.970166</td>\n",
       "      <td>-113.136972</td>\n",
       "      <td>154.850759</td>\n",
       "      <td>69.827290</td>\n",
       "      <td>...</td>\n",
       "      <td>-76.200763</td>\n",
       "      <td>145.314141</td>\n",
       "      <td>13.813910</td>\n",
       "      <td>-94.362157</td>\n",
       "      <td>-0.293851</td>\n",
       "      <td>-5.849148</td>\n",
       "      <td>-26.091699</td>\n",
       "      <td>10.898056</td>\n",
       "      <td>-101.733361</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149848</th>\n",
       "      <td>148</td>\n",
       "      <td>-17.793418</td>\n",
       "      <td>150.817466</td>\n",
       "      <td>73.632532</td>\n",
       "      <td>-25.706968</td>\n",
       "      <td>168.047285</td>\n",
       "      <td>59.618434</td>\n",
       "      <td>-111.718866</td>\n",
       "      <td>150.049738</td>\n",
       "      <td>67.477089</td>\n",
       "      <td>...</td>\n",
       "      <td>-75.753837</td>\n",
       "      <td>144.461859</td>\n",
       "      <td>13.732890</td>\n",
       "      <td>-93.925448</td>\n",
       "      <td>-0.767729</td>\n",
       "      <td>-6.155443</td>\n",
       "      <td>-25.252664</td>\n",
       "      <td>9.630910</td>\n",
       "      <td>-100.932117</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149849</th>\n",
       "      <td>149</td>\n",
       "      <td>-18.947602</td>\n",
       "      <td>157.239340</td>\n",
       "      <td>76.616787</td>\n",
       "      <td>-25.858632</td>\n",
       "      <td>169.038715</td>\n",
       "      <td>59.970166</td>\n",
       "      <td>-113.300894</td>\n",
       "      <td>157.279148</td>\n",
       "      <td>70.737581</td>\n",
       "      <td>...</td>\n",
       "      <td>-76.200763</td>\n",
       "      <td>145.314141</td>\n",
       "      <td>13.813910</td>\n",
       "      <td>-94.353292</td>\n",
       "      <td>0.039808</td>\n",
       "      <td>-5.879206</td>\n",
       "      <td>-25.986786</td>\n",
       "      <td>11.126156</td>\n",
       "      <td>-101.695434</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149850 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        rpx         rpy        rpz        lpx         lpy  \\\n",
       "0           0  -6.608069   59.958247  19.360842  -9.343826   68.774876   \n",
       "1           1 -11.372660  102.337328  34.634097 -16.858438  124.085888   \n",
       "2           2 -11.398428  102.826734  34.457183 -16.759562  123.358112   \n",
       "3           3 -11.409317  102.759617  34.605644 -16.858438  124.085888   \n",
       "4           4 -11.357979  102.578288  34.388012 -16.759562  123.358112   \n",
       "...       ...        ...         ...        ...        ...         ...   \n",
       "149845    145 -18.958171  154.817277  75.649850 -25.858632  169.038715   \n",
       "149846    146 -18.299899  152.024028  74.276472 -25.706968  168.047285   \n",
       "149847    147 -18.774816  155.144610  75.676438 -25.858632  169.038715   \n",
       "149848    148 -17.793418  150.817466  73.632532 -25.706968  168.047285   \n",
       "149849    149 -18.947602  157.239340  76.616787 -25.858632  169.038715   \n",
       "\n",
       "              lpz        rf0x        rf0y       rf0z  ...       lf4x  \\\n",
       "0       20.247514   -6.508840   63.852178   5.695187  ... -41.814304   \n",
       "1       36.531230  -92.139376  104.732563  12.983442  ... -75.442740   \n",
       "2       36.316970  -76.298842  106.069364  12.435599  ... -75.000260   \n",
       "3       36.531230  -85.918522  105.472387  12.853721  ... -75.442740   \n",
       "4       36.316970  -79.137049  105.614143  12.572882  ... -75.000260   \n",
       "...           ...         ...         ...        ...  ...        ...   \n",
       "149845  59.970166 -113.173476  154.421146  69.900119  ... -76.200763   \n",
       "149846  59.618434 -112.106843  151.445335  68.398810  ... -75.753837   \n",
       "149847  59.970166 -113.136972  154.850759  69.827290  ... -76.200763   \n",
       "149848  59.618434 -111.718866  150.049738  67.477089  ... -75.753837   \n",
       "149849  59.970166 -113.300894  157.279148  70.737581  ... -76.200763   \n",
       "\n",
       "              lf4y       lf4z      drf0x     drf0y      drf0z      drf1x  \\\n",
       "0        60.980294   2.524857   0.099229  3.893931 -13.665656  -1.438373   \n",
       "1       110.022647   4.555429 -80.766716  2.395235 -21.650654 -24.435209   \n",
       "2       109.377353   4.528711 -64.900413  3.242630 -22.021584 -20.133036   \n",
       "3       110.022647   4.555429 -74.509205  2.712770 -21.751923 -22.770234   \n",
       "4       109.377353   4.528711 -67.779070  3.035854 -21.815130 -20.928603   \n",
       "...            ...        ...        ...       ...        ...        ...   \n",
       "149845  145.314141  13.813910 -94.215305 -0.396131  -5.749732 -26.478814   \n",
       "149846  144.461859  13.732890 -93.806944 -0.578693  -5.877662 -25.733438   \n",
       "149847  145.314141  13.813910 -94.362157 -0.293851  -5.849148 -26.091699   \n",
       "149848  144.461859  13.732890 -93.925448 -0.767729  -6.155443 -25.252664   \n",
       "149849  145.314141  13.813910 -94.353292  0.039808  -5.879206 -25.986786   \n",
       "\n",
       "            drf1y       drf1z  label  \n",
       "0        3.969895  -50.970593      0  \n",
       "1       23.184260  -90.575245      0  \n",
       "2       19.964372  -90.307978      0  \n",
       "3       21.873154  -90.686315      0  \n",
       "4       20.470597  -90.263742      0  \n",
       "...           ...         ...    ...  \n",
       "149845  10.788288 -101.673058     13  \n",
       "149846   9.947693 -100.753324     13  \n",
       "149847  10.898056 -101.733361     13  \n",
       "149848   9.630910 -100.932117     13  \n",
       "149849  11.126156 -101.695434     13  \n",
       "\n",
       "[149850 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = pd.DataFrame()\n",
    "test_dataset = pd.DataFrame()\n",
    "\n",
    "for subject in subjects:\n",
    "    for gesture in config.GESTURES:\n",
    "        gesture_dir = os.path.join(data_dir, subject, gesture)\n",
    "        recordings = os.listdir(gesture_dir)\n",
    "        for recording in recordings:\n",
    "            file_path = os.path.join(gesture_dir, recording)\n",
    "            data = pd.read_csv(file_path)\n",
    "            data.drop(columns=[\"time\"], inplace=True)\n",
    "            data = data.apply(resample, args=(config.SEGMENT_LEN, None, 0))\n",
    "            \n",
    "            for_training = subject != test_subject\n",
    "\n",
    "        #     # ... calculating distance of the index finger\n",
    "        #     data[\"drf1\"] = ((data[\"rf1x\"] - data[\"rpx\"]).pow(2) + \\\n",
    "        #             (data[\"rf1z\"] - data[\"rpz\"]).pow(2)).pow(0.5)\n",
    "\n",
    "        #     data[\"dlf1\"] = ((data[\"lf1x\"] - data[\"lpx\"]).pow(2) + \\\n",
    "        #             (data[\"lf1z\"] - data[\"lpz\"]).pow(2)).pow(0.5)\n",
    "\n",
    "            data[\"drf0x\"] = data[\"rf0x\"] - data[\"rpx\"]\n",
    "            data[\"drf0y\"] = data[\"rf0y\"] - data[\"rpy\"]\n",
    "            data[\"drf0z\"] = data[\"rf0z\"] - data[\"rpz\"]\n",
    "\n",
    "            data[\"drf1x\"] = data[\"rf1x\"] - data[\"rpx\"]\n",
    "            data[\"drf1y\"] = data[\"rf1y\"] - data[\"rpy\"]\n",
    "            data[\"drf1z\"] = data[\"rf1z\"] - data[\"rpz\"]\n",
    "\n",
    "            data[\"label\"] = config.GESTURES.index(gesture)\n",
    "\n",
    "            if for_training:\n",
    "                train_dataset = pd.concat([train_dataset, data])\n",
    "            else:\n",
    "                test_dataset = pd.concat([test_dataset, data])\n",
    "\n",
    "train_dataset.reset_index(inplace=True)\n",
    "test_dataset.reset_index(inplace=True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaler Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# features = dataset[[\"drf0x\", \"drf0y\", \"drf0z\", \"drf1x\", \"drf1y\", \"drf1z\"]]\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(features)\n",
    "# scaler.data_max_ - scaler.data_min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rpx</th>\n",
       "      <th>rpy</th>\n",
       "      <th>rpz</th>\n",
       "      <th>rf0x</th>\n",
       "      <th>rf0y</th>\n",
       "      <th>rf0z</th>\n",
       "      <th>rf1x</th>\n",
       "      <th>rf1y</th>\n",
       "      <th>rf1z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.608069</td>\n",
       "      <td>59.958247</td>\n",
       "      <td>19.360842</td>\n",
       "      <td>-6.508840</td>\n",
       "      <td>63.852178</td>\n",
       "      <td>5.695187</td>\n",
       "      <td>-8.046442</td>\n",
       "      <td>63.928142</td>\n",
       "      <td>-31.609751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11.372660</td>\n",
       "      <td>102.337328</td>\n",
       "      <td>34.634097</td>\n",
       "      <td>-92.139376</td>\n",
       "      <td>104.732563</td>\n",
       "      <td>12.983442</td>\n",
       "      <td>-35.807870</td>\n",
       "      <td>125.521588</td>\n",
       "      <td>-55.941148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.398428</td>\n",
       "      <td>102.826734</td>\n",
       "      <td>34.457183</td>\n",
       "      <td>-76.298842</td>\n",
       "      <td>106.069364</td>\n",
       "      <td>12.435599</td>\n",
       "      <td>-31.531465</td>\n",
       "      <td>122.791106</td>\n",
       "      <td>-55.850795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11.409317</td>\n",
       "      <td>102.759617</td>\n",
       "      <td>34.605644</td>\n",
       "      <td>-85.918522</td>\n",
       "      <td>105.472387</td>\n",
       "      <td>12.853721</td>\n",
       "      <td>-34.179551</td>\n",
       "      <td>124.632771</td>\n",
       "      <td>-56.080671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11.357979</td>\n",
       "      <td>102.578288</td>\n",
       "      <td>34.388012</td>\n",
       "      <td>-79.137049</td>\n",
       "      <td>105.614143</td>\n",
       "      <td>12.572882</td>\n",
       "      <td>-32.286582</td>\n",
       "      <td>123.048885</td>\n",
       "      <td>-55.875731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149845</th>\n",
       "      <td>-18.958171</td>\n",
       "      <td>154.817277</td>\n",
       "      <td>75.649850</td>\n",
       "      <td>-113.173476</td>\n",
       "      <td>154.421146</td>\n",
       "      <td>69.900119</td>\n",
       "      <td>-45.436985</td>\n",
       "      <td>165.605565</td>\n",
       "      <td>-26.023208</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149846</th>\n",
       "      <td>-18.299899</td>\n",
       "      <td>152.024028</td>\n",
       "      <td>74.276472</td>\n",
       "      <td>-112.106843</td>\n",
       "      <td>151.445335</td>\n",
       "      <td>68.398810</td>\n",
       "      <td>-44.033338</td>\n",
       "      <td>161.971722</td>\n",
       "      <td>-26.476851</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149847</th>\n",
       "      <td>-18.774816</td>\n",
       "      <td>155.144610</td>\n",
       "      <td>75.676438</td>\n",
       "      <td>-113.136972</td>\n",
       "      <td>154.850759</td>\n",
       "      <td>69.827290</td>\n",
       "      <td>-44.866515</td>\n",
       "      <td>166.042666</td>\n",
       "      <td>-26.056923</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149848</th>\n",
       "      <td>-17.793418</td>\n",
       "      <td>150.817466</td>\n",
       "      <td>73.632532</td>\n",
       "      <td>-111.718866</td>\n",
       "      <td>150.049738</td>\n",
       "      <td>67.477089</td>\n",
       "      <td>-43.046082</td>\n",
       "      <td>160.448376</td>\n",
       "      <td>-27.299585</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149849</th>\n",
       "      <td>-18.947602</td>\n",
       "      <td>157.239340</td>\n",
       "      <td>76.616787</td>\n",
       "      <td>-113.300894</td>\n",
       "      <td>157.279148</td>\n",
       "      <td>70.737581</td>\n",
       "      <td>-44.934388</td>\n",
       "      <td>168.365496</td>\n",
       "      <td>-25.078647</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149850 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              rpx         rpy        rpz        rf0x        rf0y       rf0z  \\\n",
       "0       -6.608069   59.958247  19.360842   -6.508840   63.852178   5.695187   \n",
       "1      -11.372660  102.337328  34.634097  -92.139376  104.732563  12.983442   \n",
       "2      -11.398428  102.826734  34.457183  -76.298842  106.069364  12.435599   \n",
       "3      -11.409317  102.759617  34.605644  -85.918522  105.472387  12.853721   \n",
       "4      -11.357979  102.578288  34.388012  -79.137049  105.614143  12.572882   \n",
       "...           ...         ...        ...         ...         ...        ...   \n",
       "149845 -18.958171  154.817277  75.649850 -113.173476  154.421146  69.900119   \n",
       "149846 -18.299899  152.024028  74.276472 -112.106843  151.445335  68.398810   \n",
       "149847 -18.774816  155.144610  75.676438 -113.136972  154.850759  69.827290   \n",
       "149848 -17.793418  150.817466  73.632532 -111.718866  150.049738  67.477089   \n",
       "149849 -18.947602  157.239340  76.616787 -113.300894  157.279148  70.737581   \n",
       "\n",
       "             rf1x        rf1y       rf1z  label  \n",
       "0       -8.046442   63.928142 -31.609751      0  \n",
       "1      -35.807870  125.521588 -55.941148      0  \n",
       "2      -31.531465  122.791106 -55.850795      0  \n",
       "3      -34.179551  124.632771 -56.080671      0  \n",
       "4      -32.286582  123.048885 -55.875731      0  \n",
       "...           ...         ...        ...    ...  \n",
       "149845 -45.436985  165.605565 -26.023208     13  \n",
       "149846 -44.033338  161.971722 -26.476851     13  \n",
       "149847 -44.866515  166.042666 -26.056923     13  \n",
       "149848 -43.046082  160.448376 -27.299585     13  \n",
       "149849 -44.934388  168.365496 -25.078647     13  \n",
       "\n",
       "[149850 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = train_dataset[config.INFERENCE_FEATURES + [\"label\"]]\n",
    "test_features = test_dataset[config.INFERENCE_FEATURES + [\"label\"]]\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 17:12:34.821380: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models, losses, optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 150, 9)\n",
      "(168, 150, 9)\n",
      "(999, 1)\n",
      "(168, 1)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# X = features.drop(columns=[\"label\"]).to_numpy()\n",
    "# X = scaler.fit_transform(X)\n",
    "# X = X.reshape((-1, config.SEGMENT_LEN, len(config.INFERENCE_FEATURES)))\n",
    "# y = features[\"label\"].to_numpy().reshape((-1, config.SEGMENT_LEN))\n",
    "# y, _ = mode(y, axis=1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.33, random_state=42\n",
    "# )\n",
    "\n",
    "X_train = train_features.drop(columns=[\"label\"]).to_numpy()\n",
    "X_test = test_features.drop(columns=[\"label\"]).to_numpy()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape((-1, config.SEGMENT_LEN, len(config.INFERENCE_FEATURES)))\n",
    "X_test = X_test.reshape((-1, config.SEGMENT_LEN, len(config.INFERENCE_FEATURES)))\n",
    "\n",
    "y_train = train_features[\"label\"].to_numpy().reshape((-1, config.SEGMENT_LEN))\n",
    "y_test = test_features[\"label\"].to_numpy().reshape((-1, config.SEGMENT_LEN))\n",
    "\n",
    "y_train, _ = mode(y_train, axis=1)\n",
    "y_test, _ = mode(y_test, axis=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_1d():\n",
    "    inputs = layers.Input(shape=(config.SEGMENT_LEN, 1))\n",
    "    x = layers.BatchNormalization()(inputs)\n",
    "    x = layers.Conv1D(8, 3, activation=\"selu\")(x)\n",
    "    x = layers.Conv1D(8, 3, activation=\"selu\")(x)\n",
    "    x = layers.MaxPool1D(2)(x)\n",
    "    x = layers.Conv1D(8, 3, activation=\"selu\")(x)\n",
    "    x = layers.Conv1D(8, 3, activation=\"selu\")(x)\n",
    "    x = layers.MaxPool1D(2)(x)\n",
    "    x = layers.Conv1D(16, 3, activation=\"selu\")(x)\n",
    "    x = layers.Conv1D(16, 3, activation=\"selu\")(x)\n",
    "    x = layers.MaxPool1D(2)(x)\n",
    "    x = layers.Conv1D(16, 3, activation=\"selu\")(x)\n",
    "    x = layers.Conv1D(16, 3, activation=\"selu\")(x)\n",
    "    x = layers.MaxPool1D(2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(64)(x)\n",
    "\n",
    "    return inputs, output\n",
    "\n",
    "def get_model(n_channels: int):\n",
    "    inputs = []\n",
    "    features = []\n",
    "\n",
    "    for _ in range(n_channels):\n",
    "        input_1d, features_1d = conv_block_1d()\n",
    "        inputs.append(input_1d)\n",
    "        features.append(features_1d)\n",
    "\n",
    "    x = layers.concatenate(features, axis=-1)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(len(gestures), activation=\"softmax\")(x)\n",
    "\n",
    "    return models.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 17:12:36.035664: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-26 17:12:36.035695: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: Andromeda\n",
      "2022-06-26 17:12:36.035700: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: Andromeda\n",
      "2022-06-26 17:12:36.035810: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.48.7\n",
      "2022-06-26 17:12:36.035827: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.48.7\n",
      "2022-06-26 17:12:36.035831: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.48.7\n",
      "2022-06-26 17:12:36.036099: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = get_model(n_channels=len(config.INFERENCE_FEATURES))\n",
    "\n",
    "loss = losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 [==============================] - 5s 41ms/step - loss: 2.9581 - accuracy: 0.1261 - val_loss: 2.6082 - val_accuracy: 0.1607\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 2.1846 - accuracy: 0.2853 - val_loss: 2.5201 - val_accuracy: 0.2679\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 1.8905 - accuracy: 0.3844 - val_loss: 2.3295 - val_accuracy: 0.3036\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.6740 - accuracy: 0.4685 - val_loss: 2.0731 - val_accuracy: 0.3631\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.4363 - accuracy: 0.5325 - val_loss: 1.8096 - val_accuracy: 0.4048\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.3022 - accuracy: 0.5956 - val_loss: 1.6545 - val_accuracy: 0.4524\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1359 - accuracy: 0.6346 - val_loss: 1.4199 - val_accuracy: 0.5655\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1471 - accuracy: 0.6406 - val_loss: 1.3022 - val_accuracy: 0.6726\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.9835 - accuracy: 0.6767 - val_loss: 1.2056 - val_accuracy: 0.6786\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.8795 - accuracy: 0.7167 - val_loss: 1.0917 - val_accuracy: 0.7619\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8883 - accuracy: 0.7137 - val_loss: 1.0440 - val_accuracy: 0.7262\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.8258 - accuracy: 0.7317 - val_loss: 0.9088 - val_accuracy: 0.7917\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.6967 - accuracy: 0.7808 - val_loss: 0.8897 - val_accuracy: 0.7857\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.6856 - accuracy: 0.7698 - val_loss: 0.9775 - val_accuracy: 0.7619\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.6578 - accuracy: 0.7938 - val_loss: 0.8895 - val_accuracy: 0.7738\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5979 - accuracy: 0.8018 - val_loss: 0.9013 - val_accuracy: 0.7738\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5696 - accuracy: 0.8108 - val_loss: 0.9223 - val_accuracy: 0.7619\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5707 - accuracy: 0.8208 - val_loss: 0.8575 - val_accuracy: 0.7381\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5185 - accuracy: 0.8408 - val_loss: 0.9434 - val_accuracy: 0.7381\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.4564 - accuracy: 0.8458 - val_loss: 0.9335 - val_accuracy: 0.7560\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.4684 - accuracy: 0.8569 - val_loss: 0.9823 - val_accuracy: 0.7679\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.4830 - accuracy: 0.8488 - val_loss: 1.0467 - val_accuracy: 0.7202\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.4541 - accuracy: 0.8619 - val_loss: 1.0227 - val_accuracy: 0.7500\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.4310 - accuracy: 0.8629 - val_loss: 0.9395 - val_accuracy: 0.7619\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.4074 - accuracy: 0.8719 - val_loss: 0.9730 - val_accuracy: 0.7500\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.4281 - accuracy: 0.8659 - val_loss: 0.8317 - val_accuracy: 0.7798\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.4015 - accuracy: 0.8729 - val_loss: 0.8209 - val_accuracy: 0.7917\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.3942 - accuracy: 0.8749 - val_loss: 0.9277 - val_accuracy: 0.7619\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.3825 - accuracy: 0.8839 - val_loss: 0.8685 - val_accuracy: 0.7560\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.3668 - accuracy: 0.8829 - val_loss: 0.9091 - val_accuracy: 0.7143\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.3620 - accuracy: 0.8959 - val_loss: 0.8026 - val_accuracy: 0.7857\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.3508 - accuracy: 0.8809 - val_loss: 0.7969 - val_accuracy: 0.7798\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.3896 - accuracy: 0.8759 - val_loss: 0.8722 - val_accuracy: 0.7679\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.3075 - accuracy: 0.9049 - val_loss: 0.8602 - val_accuracy: 0.7440\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.2872 - accuracy: 0.9089 - val_loss: 0.9081 - val_accuracy: 0.7381\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.3195 - accuracy: 0.8879 - val_loss: 0.9918 - val_accuracy: 0.7381\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.2824 - accuracy: 0.8979 - val_loss: 0.7914 - val_accuracy: 0.8095\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.2815 - accuracy: 0.9149 - val_loss: 0.8695 - val_accuracy: 0.7619\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.2756 - accuracy: 0.9189 - val_loss: 0.8945 - val_accuracy: 0.7560\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.2566 - accuracy: 0.9169 - val_loss: 1.0528 - val_accuracy: 0.7381\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.2888 - accuracy: 0.8959 - val_loss: 0.9010 - val_accuracy: 0.7560\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.2554 - accuracy: 0.9199 - val_loss: 0.8391 - val_accuracy: 0.7560\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.2504 - accuracy: 0.9149 - val_loss: 0.9158 - val_accuracy: 0.7560\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.2495 - accuracy: 0.9209 - val_loss: 0.9601 - val_accuracy: 0.7440\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.2619 - accuracy: 0.9119 - val_loss: 0.8797 - val_accuracy: 0.7321\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.2384 - accuracy: 0.9229 - val_loss: 0.8061 - val_accuracy: 0.7976\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.2262 - accuracy: 0.9249 - val_loss: 0.8521 - val_accuracy: 0.7738\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.2522 - accuracy: 0.9109 - val_loss: 1.1514 - val_accuracy: 0.7321\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.2653 - accuracy: 0.9039 - val_loss: 0.9339 - val_accuracy: 0.7619\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.2155 - accuracy: 0.9289 - val_loss: 1.0689 - val_accuracy: 0.7143\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.2528 - accuracy: 0.9259 - val_loss: 0.9428 - val_accuracy: 0.7738\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.2220 - accuracy: 0.9299 - val_loss: 1.0596 - val_accuracy: 0.7619\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.2476 - accuracy: 0.9179 - val_loss: 0.8729 - val_accuracy: 0.8095\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.2075 - accuracy: 0.9329 - val_loss: 1.0333 - val_accuracy: 0.7321\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.2119 - accuracy: 0.9299 - val_loss: 0.7935 - val_accuracy: 0.7798\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.2199 - accuracy: 0.9169 - val_loss: 0.9144 - val_accuracy: 0.7619\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.2196 - accuracy: 0.9219 - val_loss: 0.8497 - val_accuracy: 0.7798\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.2336 - accuracy: 0.9179 - val_loss: 0.8802 - val_accuracy: 0.7857\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1976 - accuracy: 0.9279 - val_loss: 0.8249 - val_accuracy: 0.7857\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.2027 - accuracy: 0.9299 - val_loss: 0.9109 - val_accuracy: 0.7976\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1902 - accuracy: 0.9349 - val_loss: 0.9960 - val_accuracy: 0.7798\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1603 - accuracy: 0.9429 - val_loss: 0.9590 - val_accuracy: 0.7440\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1814 - accuracy: 0.9299 - val_loss: 0.9152 - val_accuracy: 0.7917\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.2187 - accuracy: 0.9209 - val_loss: 0.8548 - val_accuracy: 0.7976\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1865 - accuracy: 0.9419 - val_loss: 0.8100 - val_accuracy: 0.7679\n",
      "Epoch 66/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1707 - accuracy: 0.9429 - val_loss: 0.8637 - val_accuracy: 0.7917\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.1863 - accuracy: 0.9309 - val_loss: 0.8386 - val_accuracy: 0.8095\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1730 - accuracy: 0.9379 - val_loss: 0.9622 - val_accuracy: 0.7976\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1844 - accuracy: 0.9339 - val_loss: 0.9823 - val_accuracy: 0.7857\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1884 - accuracy: 0.9389 - val_loss: 0.9972 - val_accuracy: 0.7857\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1638 - accuracy: 0.9499 - val_loss: 0.8695 - val_accuracy: 0.7917\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1853 - accuracy: 0.9359 - val_loss: 0.9117 - val_accuracy: 0.8095\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1794 - accuracy: 0.9359 - val_loss: 1.0666 - val_accuracy: 0.7738\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1769 - accuracy: 0.9369 - val_loss: 1.0217 - val_accuracy: 0.7738\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1604 - accuracy: 0.9419 - val_loss: 0.8472 - val_accuracy: 0.8095\n",
      "Epoch 76/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1701 - accuracy: 0.9479 - val_loss: 0.9504 - val_accuracy: 0.7798\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1716 - accuracy: 0.9429 - val_loss: 0.9494 - val_accuracy: 0.7798\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1534 - accuracy: 0.9479 - val_loss: 1.0526 - val_accuracy: 0.7917\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1867 - accuracy: 0.9389 - val_loss: 0.8975 - val_accuracy: 0.7738\n",
      "Epoch 80/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1587 - accuracy: 0.9419 - val_loss: 0.7735 - val_accuracy: 0.7976\n",
      "Epoch 81/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1516 - accuracy: 0.9479 - val_loss: 0.9051 - val_accuracy: 0.7917\n",
      "Epoch 82/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.1551 - accuracy: 0.9520 - val_loss: 0.9043 - val_accuracy: 0.7798\n",
      "Epoch 83/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1380 - accuracy: 0.9530 - val_loss: 0.9467 - val_accuracy: 0.7798\n",
      "Epoch 84/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1523 - accuracy: 0.9459 - val_loss: 1.0132 - val_accuracy: 0.7976\n",
      "Epoch 85/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1372 - accuracy: 0.9510 - val_loss: 0.9711 - val_accuracy: 0.8095\n",
      "Epoch 86/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1511 - accuracy: 0.9499 - val_loss: 0.9265 - val_accuracy: 0.7917\n",
      "Epoch 87/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1518 - accuracy: 0.9479 - val_loss: 1.0350 - val_accuracy: 0.7917\n",
      "Epoch 88/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1487 - accuracy: 0.9439 - val_loss: 1.0064 - val_accuracy: 0.7976\n",
      "Epoch 89/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1365 - accuracy: 0.9489 - val_loss: 1.0416 - val_accuracy: 0.7976\n",
      "Epoch 90/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1486 - accuracy: 0.9459 - val_loss: 1.0186 - val_accuracy: 0.7619\n",
      "Epoch 91/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1510 - accuracy: 0.9520 - val_loss: 1.1196 - val_accuracy: 0.7857\n",
      "Epoch 92/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1677 - accuracy: 0.9419 - val_loss: 0.9542 - val_accuracy: 0.8214\n",
      "Epoch 93/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1226 - accuracy: 0.9590 - val_loss: 0.9699 - val_accuracy: 0.7738\n",
      "Epoch 94/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1311 - accuracy: 0.9600 - val_loss: 0.9911 - val_accuracy: 0.8155\n",
      "Epoch 95/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1298 - accuracy: 0.9600 - val_loss: 0.8704 - val_accuracy: 0.7976\n",
      "Epoch 96/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1385 - accuracy: 0.9469 - val_loss: 0.8966 - val_accuracy: 0.8333\n",
      "Epoch 97/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1404 - accuracy: 0.9520 - val_loss: 0.7758 - val_accuracy: 0.8393\n",
      "Epoch 98/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1244 - accuracy: 0.9650 - val_loss: 0.7773 - val_accuracy: 0.8333\n",
      "Epoch 99/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.1483 - accuracy: 0.9459 - val_loss: 0.8446 - val_accuracy: 0.8036\n",
      "Epoch 100/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1256 - accuracy: 0.9520 - val_loss: 0.8428 - val_accuracy: 0.8333\n",
      "Epoch 101/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1252 - accuracy: 0.9530 - val_loss: 0.9180 - val_accuracy: 0.7857\n",
      "Epoch 102/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1315 - accuracy: 0.9550 - val_loss: 0.8403 - val_accuracy: 0.8155\n",
      "Epoch 103/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1438 - accuracy: 0.9540 - val_loss: 0.9618 - val_accuracy: 0.7976\n",
      "Epoch 104/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1772 - accuracy: 0.9439 - val_loss: 0.9848 - val_accuracy: 0.7857\n",
      "Epoch 105/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.1299 - accuracy: 0.9489 - val_loss: 0.9725 - val_accuracy: 0.8274\n",
      "Epoch 106/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0961 - accuracy: 0.9750 - val_loss: 1.0846 - val_accuracy: 0.8036\n",
      "Epoch 107/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1170 - accuracy: 0.9600 - val_loss: 0.9705 - val_accuracy: 0.8036\n",
      "Epoch 108/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1407 - accuracy: 0.9540 - val_loss: 0.8071 - val_accuracy: 0.8512\n",
      "Epoch 109/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1190 - accuracy: 0.9630 - val_loss: 0.8397 - val_accuracy: 0.8393\n",
      "Epoch 110/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.1099 - accuracy: 0.9690 - val_loss: 0.8692 - val_accuracy: 0.7738\n",
      "Epoch 111/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1277 - accuracy: 0.9600 - val_loss: 0.8989 - val_accuracy: 0.8333\n",
      "Epoch 112/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1297 - accuracy: 0.9550 - val_loss: 0.9176 - val_accuracy: 0.7976\n",
      "Epoch 113/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1266 - accuracy: 0.9570 - val_loss: 0.9298 - val_accuracy: 0.8095\n",
      "Epoch 114/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1086 - accuracy: 0.9670 - val_loss: 1.0567 - val_accuracy: 0.7976\n",
      "Epoch 115/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1197 - accuracy: 0.9650 - val_loss: 0.9823 - val_accuracy: 0.7917\n",
      "Epoch 116/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.1260 - accuracy: 0.9620 - val_loss: 1.0540 - val_accuracy: 0.7917\n",
      "Epoch 117/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1123 - accuracy: 0.9630 - val_loss: 0.9971 - val_accuracy: 0.7917\n",
      "Epoch 118/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1107 - accuracy: 0.9600 - val_loss: 1.0968 - val_accuracy: 0.7798\n",
      "Epoch 119/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1170 - accuracy: 0.9640 - val_loss: 1.0441 - val_accuracy: 0.8155\n",
      "Epoch 120/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1022 - accuracy: 0.9650 - val_loss: 0.9240 - val_accuracy: 0.8095\n",
      "Epoch 121/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1217 - accuracy: 0.9600 - val_loss: 1.0479 - val_accuracy: 0.7857\n",
      "Epoch 122/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1035 - accuracy: 0.9640 - val_loss: 1.0387 - val_accuracy: 0.8274\n",
      "Epoch 123/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.1265 - accuracy: 0.9550 - val_loss: 0.9765 - val_accuracy: 0.8333\n",
      "Epoch 124/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1176 - accuracy: 0.9650 - val_loss: 0.9895 - val_accuracy: 0.8333\n",
      "Epoch 125/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.1007 - accuracy: 0.9650 - val_loss: 0.8493 - val_accuracy: 0.8095\n",
      "Epoch 126/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.1079 - accuracy: 0.9680 - val_loss: 0.9922 - val_accuracy: 0.8095\n",
      "Epoch 127/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.1314 - accuracy: 0.9540 - val_loss: 1.0014 - val_accuracy: 0.8214\n",
      "Epoch 128/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.1321 - accuracy: 0.9520 - val_loss: 1.2127 - val_accuracy: 0.7738\n",
      "Epoch 129/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.1148 - accuracy: 0.9610 - val_loss: 1.1727 - val_accuracy: 0.8036\n",
      "Epoch 130/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.1065 - accuracy: 0.9650 - val_loss: 1.2205 - val_accuracy: 0.7619\n",
      "Epoch 131/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1104 - accuracy: 0.9620 - val_loss: 1.0962 - val_accuracy: 0.8036\n",
      "Epoch 132/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0941 - accuracy: 0.9600 - val_loss: 1.0503 - val_accuracy: 0.8274\n",
      "Epoch 133/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0976 - accuracy: 0.9650 - val_loss: 1.0685 - val_accuracy: 0.8214\n",
      "Epoch 134/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.1383 - accuracy: 0.9540 - val_loss: 1.0981 - val_accuracy: 0.8393\n",
      "Epoch 135/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1364 - accuracy: 0.9520 - val_loss: 0.8568 - val_accuracy: 0.8333\n",
      "Epoch 136/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0947 - accuracy: 0.9620 - val_loss: 0.9372 - val_accuracy: 0.8571\n",
      "Epoch 137/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0994 - accuracy: 0.9690 - val_loss: 0.9730 - val_accuracy: 0.8155\n",
      "Epoch 138/300\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.1382 - accuracy: 0.9550 - val_loss: 0.8195 - val_accuracy: 0.8274\n",
      "Epoch 139/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0862 - accuracy: 0.9710 - val_loss: 0.9899 - val_accuracy: 0.8155\n",
      "Epoch 140/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.1064 - accuracy: 0.9720 - val_loss: 0.9862 - val_accuracy: 0.8512\n",
      "Epoch 141/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0824 - accuracy: 0.9720 - val_loss: 0.9795 - val_accuracy: 0.8333\n",
      "Epoch 142/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0986 - accuracy: 0.9600 - val_loss: 1.0705 - val_accuracy: 0.8274\n",
      "Epoch 143/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0841 - accuracy: 0.9670 - val_loss: 1.0246 - val_accuracy: 0.8095\n",
      "Epoch 144/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0902 - accuracy: 0.9710 - val_loss: 1.0532 - val_accuracy: 0.8036\n",
      "Epoch 145/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0913 - accuracy: 0.9700 - val_loss: 1.0579 - val_accuracy: 0.7917\n",
      "Epoch 146/300\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0792 - accuracy: 0.9740 - val_loss: 1.2776 - val_accuracy: 0.8095\n",
      "Epoch 147/300\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0843 - accuracy: 0.9680 - val_loss: 1.2832 - val_accuracy: 0.7976\n",
      "Epoch 148/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0966 - accuracy: 0.9700 - val_loss: 0.9331 - val_accuracy: 0.8452\n",
      "Epoch 149/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1227 - accuracy: 0.9590 - val_loss: 1.1365 - val_accuracy: 0.7857\n",
      "Epoch 150/300\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.1023 - accuracy: 0.9620 - val_loss: 1.1421 - val_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=30,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    x=np.split(X_train, len(config.INFERENCE_FEATURES), axis=-1),\n",
    "    y=y_train,\n",
    "    validation_data=(\n",
    "        np.split(X_test, len(config.INFERENCE_FEATURES), axis=-1),\n",
    "        y_test\n",
    "    ),\n",
    "    batch_size=32,\n",
    "    epochs=300,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7735 - accuracy: 0.7976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7735306620597839, 0.7976190447807312]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(np.split(X_test, len(config.INFERENCE_FEATURES), axis=-1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\n",
    "    # \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    # \"font.serif\": [\"Computer Modern Roman\"],\n",
    "    \"font.size\": 22,\n",
    "    \"text.color\": \"#212121\",\n",
    "    \"axes.edgecolor\": \"#212121\",\n",
    "    \"xtick.color\": \"#212121\",\n",
    "    \"ytick.color\": \"#212121\",\n",
    "    \"axes.labelcolor\": \"#212121\",\n",
    "    'legend.frameon': False,\n",
    "})\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.gca()\n",
    "ax.plot(history.history[\"loss\"], \"-\", color=\"#212121\", label=\"Train Loss\")\n",
    "ax.plot(history.history[\"val_loss\"], \"--\", color=\"#212121\", label=\"Validation Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.title(\"Learning Curves\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../models/scaler.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ai/Web/Sign-Language-Recognition/core/src/notebooks/AlgorithmDL.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ai/Web/Sign-Language-Recognition/core/src/notebooks/AlgorithmDL.ipynb#ch0000013?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjoblib\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ai/Web/Sign-Language-Recognition/core/src/notebooks/AlgorithmDL.ipynb#ch0000013?line=1'>2</a>\u001b[0m joblib\u001b[39m.\u001b[39;49mdump(scaler, \u001b[39m\"\u001b[39;49m\u001b[39m../../models/scaler.joblib\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ai/Web/Sign-Language-Recognition/core/src/notebooks/AlgorithmDL.ipynb#ch0000013?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39m../../models/stack_cnn\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Web/Sign-Language-Recognition/core/.env/lib/python3.10/site-packages/joblib/numpy_pickle.py:481\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    479\u001b[0m         NumpyPickler(f, protocol\u001b[39m=\u001b[39mprotocol)\u001b[39m.\u001b[39mdump(value)\n\u001b[1;32m    480\u001b[0m \u001b[39melif\u001b[39;00m is_filename:\n\u001b[0;32m--> 481\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    482\u001b[0m         NumpyPickler(f, protocol\u001b[39m=\u001b[39mprotocol)\u001b[39m.\u001b[39mdump(value)\n\u001b[1;32m    483\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../models/scaler.joblib'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, \"../../models/scaler.joblib\")\n",
    "model.save(\"../../models/stack_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f0f52ed645d8567bae68a8c372449e0a23f49f10e778396b1f58fd2946c160c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
