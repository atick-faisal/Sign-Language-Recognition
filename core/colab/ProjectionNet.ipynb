{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config(object):\n",
    "    INFERENCE_TIME = 3.0  # ... Segment duration\n",
    "    HOLD_TIME = 2.0  # ... Time before next prediction session\n",
    "    SEGMENT_LEN = 256\n",
    "    IMG_LEN = 224  # 1/9 of the 224x224 image\n",
    "    N_CHANNELS = 1\n",
    "    LEARNING_RATE = 0.0003\n",
    "    PROJECTION_LANDMARKS = [\"rp\", \"rf0\", \"rf1\"]\n",
    "    INFERENCE_FEATURES = [\n",
    "        \"rpx\",\n",
    "        \"rpy\",\n",
    "        \"rpz\",\n",
    "        \"rf0x\",\n",
    "        \"rf0y\",\n",
    "        \"rf0z\",\n",
    "        \"rf1x\",\n",
    "        \"rf1y\",\n",
    "        \"rf1z\"\n",
    "    ]\n",
    "    MODEL_PREDICTION = \"dev.atick.slr.model.prediction\"\n",
    "    FRAME_EVENT = \"dev.atick.slr.frame\"\n",
    "    GESTURES = [\"Good\", \"Bad\", \"Fine\", \"Hello\", \"Yes\", \"Deaf\", \"Me\",\n",
    "                \"No\", \"Please\", \"Sorry\", \"Thank You\", \"You\", \"Hungry\", \"Goodbye\"]\n",
    "    FEATURE_NAMES = [\n",
    "        \"time\",\n",
    "        \"rpx\",\n",
    "        \"rpy\",\n",
    "        \"rpz\",\n",
    "        \"lpx\",\n",
    "        \"lpy\",\n",
    "        \"lpz\",\n",
    "        \"rf0x\",\n",
    "        \"rf0y\",\n",
    "        \"rf0z\",\n",
    "        \"rf1x\",\n",
    "        \"rf1y\",\n",
    "        \"rf1z\",\n",
    "        \"rf2x\",\n",
    "        \"rf2y\",\n",
    "        \"rf2z\",\n",
    "        \"rf3x\",\n",
    "        \"rf3y\",\n",
    "        \"rf3z\",\n",
    "        \"rf4x\",\n",
    "        \"rf4y\",\n",
    "        \"rf4z\",\n",
    "        \"lf0x\",\n",
    "        \"lf0y\",\n",
    "        \"lf0z\",\n",
    "        \"lf1x\",\n",
    "        \"lf1y\",\n",
    "        \"lf1z\",\n",
    "        \"lf2x\",\n",
    "        \"lf2y\",\n",
    "        \"lf2z\",\n",
    "        \"lf3x\",\n",
    "        \"lf3y\",\n",
    "        \"lf3z\",\n",
    "        \"lf4x\",\n",
    "        \"lf4y\",\n",
    "        \"lf4z\",\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize(x: np.ndarray) -> np.ndarray:\n",
    "    try:\n",
    "        return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "    except ZeroDivisionError:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Pass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "\n",
    "class LowPassFilter(object):\n",
    "    def butter_lowpass(\n",
    "        cutoff: int,\n",
    "        fs: int,\n",
    "        order: int\n",
    "    ):\n",
    "        nyq = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyq\n",
    "        b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "        return b, a\n",
    "\n",
    "    def apply(\n",
    "        data: np.ndarray,\n",
    "        cutoff: int = 6,\n",
    "        fs: int = 100,\n",
    "        order: int = 2\n",
    "    ):\n",
    "        b, a = LowPassFilter.butter_lowpass(cutoff, fs, order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatical Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ahaha'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import randint\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.ticker import NullLocator\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "\n",
    "class SpatialProjection():\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_dir: str,\n",
    "        img_len: int,\n",
    "        polyfit_degree: int = 0\n",
    "    ):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_len = img_len\n",
    "        self.polyfit_degree = polyfit_degree\n",
    "\n",
    "    @staticmethod\n",
    "    def __write_image(\n",
    "        img: np.ndarray,\n",
    "        write_dir: str,\n",
    "        plane: str,\n",
    "        name: str\n",
    "    ):\n",
    "        path = os.path.join(write_dir, plane)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        cv2.imwrite(os.path.join(path, name + \".jpg\"), img)\n",
    "\n",
    "    def __get_preocessed_data(\n",
    "        self,\n",
    "        data: pd.Series\n",
    "    ) -> np.ndarray:\n",
    "        processed_data = data.to_numpy().ravel()\n",
    "\n",
    "        if self.polyfit_degree == 0:\n",
    "            # ... First few (10) datapoints contains filter artifacts\n",
    "            processed_data = LowPassFilter.apply(processed_data)[10:]\n",
    "        else:\n",
    "            t = np.linspace(0, 1, processed_data.shape[0])\n",
    "            f = np.poly1d(np.polyfit(t, processed_data, self.polyfit_degree))\n",
    "            processed_data = f(t)\n",
    "\n",
    "        return processed_data\n",
    "\n",
    "    def __generate_projection_image(\n",
    "        self,\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        img_len_inch = self.img_len / 100.0  # 100 is the Figure DPI value\n",
    "        fig = Figure(figsize=(img_len_inch, img_len_inch))\n",
    "        width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "\n",
    "        canvas = FigureCanvas(fig)\n",
    "        ax = fig.gca()\n",
    "        ax.plot(x, y, \"-k\", linewidth=2)\n",
    "        ax.axis(\"off\")\n",
    "        ax.xaxis.set_major_locator(NullLocator())\n",
    "        ax.yaxis.set_major_locator(NullLocator())\n",
    "        # fig.tight_layout()\n",
    "        canvas.draw()\n",
    "\n",
    "        image = np.frombuffer(canvas.tostring_rgb(), dtype=\"uint8\")\n",
    "        return image.reshape(int(height), int(width), 3)\n",
    "\n",
    "    def get_projection_images(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        subject: str,\n",
    "        gesture: str,\n",
    "        write_image: bool = False\n",
    "    ) -> list[np.ndarray]:\n",
    "        landmark = data.columns[0][:-1]\n",
    "        name = str(randint(100000, 999999))\n",
    "        write_dir = os.path.join(self.img_dir, subject, gesture, landmark)\n",
    "\n",
    "        x = self.__get_preocessed_data(data.filter(regex=\"x\"))\n",
    "        y = self.__get_preocessed_data(data.filter(regex=\"y\"))\n",
    "        z = self.__get_preocessed_data(data.filter(regex=\"z\"))\n",
    "\n",
    "        img_xy = self.__generate_projection_image(x, y)\n",
    "        img_yz = self.__generate_projection_image(y, z)\n",
    "        img_zx = self.__generate_projection_image(z, x)\n",
    "\n",
    "        if write_image == True:\n",
    "            self.__write_image(img_xy, write_dir, \"xy\", name)\n",
    "            self.__write_image(img_yz, write_dir, \"yz\", name)\n",
    "            self.__write_image(img_zx, write_dir, \"zx\", name)\n",
    "\n",
    "        return [img_xy, img_yz, img_zx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_levels = [0, 7, 9, 11, 13]\n",
    "sp_augment = [\n",
    "    SpatialProjection(\n",
    "    img_dir=\"images/\",\n",
    "    img_len=math.floor(config.IMG_LEN / 3),\n",
    "    polyfit_degree=degree\n",
    ")\n",
    "    for degree in augmentation_levels ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = joblib.load(\"X_train.joblib\")\n",
    "y_train = joblib.load(\"y_train.joblib\")\n",
    "X_test = joblib.load(\"X_test.joblib\")\n",
    "y_test = joblib.load(\"y_test.joblib\")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "# base_model = tf.keras.applications.MobileNetV2(\n",
    "#     input_shape=(config.IMG_LEN, config.IMG_LEN, 3),\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\"\n",
    "# )\n",
    "# base_model.trainable = True\n",
    "# global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "# prediction_layer = tf.keras.layers.Dense(len(config.GESTURES))\n",
    "\n",
    "# inputs = tf.keras.Input(shape=(config.IMG_LEN, config.IMG_LEN, 3))\n",
    "# x = preprocess_input(inputs)\n",
    "# x = base_model(x, training=True)\n",
    "# x = global_average_layer(x)\n",
    "# x = tf.keras.layers.Dropout(0.6)(x)\n",
    "# outputs = prediction_layer(x)\n",
    "# model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Rescaling(\n",
    "        1/255.0,\n",
    "        input_shape=(config.IMG_LEN, config.IMG_LEN, config.N_CHANNELS)\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(config.GESTURES))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=config.LEARNING_RATE),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=30,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=32,\n",
    "    epochs=700,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\n",
    "    # \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    # \"font.serif\": [\"Computer Modern Roman\"],\n",
    "    \"font.size\": 22,\n",
    "    \"text.color\": \"#212121\",\n",
    "    \"axes.edgecolor\": \"#212121\",\n",
    "    \"xtick.color\": \"#212121\",\n",
    "    \"ytick.color\": \"#212121\",\n",
    "    \"axes.labelcolor\": \"#212121\",\n",
    "    'legend.frameon': False,\n",
    "})\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.gca()\n",
    "ax.plot(history.history[\"loss\"], \"-\", color=\"#212121\", label=\"Train Loss\")\n",
    "ax.plot(history.history[\"val_loss\"], \"--\",\n",
    "        color=\"#212121\", label=\"Validation Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.title(\"Learning Curves\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../assets/lc.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f0f52ed645d8567bae68a8c372449e0a23f49f10e778396b1f58fd2946c160c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
